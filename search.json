[
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "August, 2015: Ph.D., History, University of North Carolina, Chapel Hill\nMay, 2010: M.A., History, University of California, Santa Barbara\nMay, 2005: B.A. / B.S., Dual major in History and Information Sciences and Technology, Pennsylvania State University\n\n\n\n2022 - present: Digital Research Specialist, Office of Advanced Research Computing, University of California, Los Angeles\n2021 - 2022: Digital Humanities Research Facilitator, Research Data Services, University of California, Santa Barbara Library\n2020 - 2021: Sinai Manuscripts Digital Library Data/Metadata Coordinator, Digital Library Program, University of California, Los Angeles Digital Library Program\n2019 - 2020: Research Associate, World History Center, History Department, University of Pittsburgh\n2017 - 2019: Post-Doctoral Fellow, World History Center, History Department, University of Pittsburgh\n2015 - 2017: Post-Doctoral Fellow, the Carolina Digital Humanities Initiative, History Department, and the Institute for the Arts and Humanities, University of North Carolina, Chapel Hill\n2014 - 2015: Director, Ancient World Mapping Center, History Department, University of North Carolina, Chapel Hill\n2010 - 2014: Digital Director, Ancient World Mapping Center, History Department, University of North Carolina, Chapel Hill\n2008 - 2010: Teaching Assistant, University of California, Santa Barbara\n2005 - 2007: Software Engineer Associate, Lockheed Martin, Owego, NY\n(Developed optical character recognition software and web resources)\n\n\n\n\n\n2020: Aeolian Alexanders: Economic, Material, and Social Networks in Antiquity Electronic publication supported by a NEH-Mellon Fellowship for Digital Publication. https://github.com/Aeolian-Alexanders\n\n\n\n2021: Bond, Sarah, Paul Dilley, and Ryan Horne (eds). Linked Open Data for the Ancient Mediterranean: Structures, Practices, Prospects. ISAW Papers 20. http://dlib.nyu.edu/awdl/isaw/isaw-papers/20/\n\n\n\n2022: Horne, Ryan and Ruth Mostern. “Landscapes in Motion: Cartographies of Connectivity and the Place of Physical Geography in the Environmental and Spatial Humanities” In Routledge Handbook of the Digital Environmental Humanities, ed. Luke Bergmann, Arlene Crampsie, Deborah Dixon, Steven Hartman, Robert Legg, Francis Ludlow, and Charlie Travis. Routledge. p. 470-489\n2021: Digital Approaches to the ‘Big Ancient Mediterranean.’” In Access and Control in Digital Humanities, ed. Shane Hawkins. Routledge. p. 78–95\n2021: Bond, Sarah, Paul Dilley, and Ryan Horne. “Introducing the Semantic Web and Linked Open Data,” in Bond, Sarah, Paul Dilley, and Ryan Horne (eds). Linked Open Data for the Ancient Mediterranean: Structures, Practices, Prospects. ISAW Papers 20. http://dlib.nyu.edu/awdl/isaw/isaw-papers/20-1/\n2021: “Applying Linked Open Data Standards,” in Bond, Sarah, Paul Dilley, and Ryan Horne (eds). Linked Open Data for the Ancient Mediterranean: Structures, Practices, Prospects. ISAW Papers 20. http://dlib.nyu.edu/awdl/isaw/isaw-papers/20-2/\n2021: Mostern, Ruth and Ryan Horne. “Tracking Yu: Developing a Data System for Yellow River History.” In Mostern, Ruth. Yellow River: A Natural and Unnatural History. Yale University Press. p. 247–266\n2020: “Mapping Power: Using HGIS and Linked Open Data to Study Ancient Greek Garrison Communities,” in Historical Geography, GIScience and Textual Analysis: Landscapes of Time and Place, ed. Charles Travis, Francis Ludlow, and Ferenc Gyuris. Springer. p. 213–227\n2014: “Beyond Maps as Images at the Ancient World Mapping Center.” in Elliott, Thomas, Sebastian Heath, and John Muccigrosso (eds). Current Practice in Linked Open Data for the Ancient World, ISAW Papers 7. http://dlib.nyu.edu/awdl/isaw/isaw-papers/7/horne/\n\n\n\n2022: Middle, Sarah, Ryan Horne, David A. McMeekin, Chiara Zuanni, and Alex Butterworth. “Geographies of Place in Digital Art History”, International Journal of Humanities and Arts Computing (IJHAC) 16, no.1: 94-109.\n2021: “Digital Tools and Ancient Empires: Using Network Analysis and Geographic Information Systems to Study Imperial Networks in Hellenistic Anatolia.” Journal of World History 32, no. 2: 321–43.\n2020: “Beyond Lists: Digital Gazetteers and Digital History,” The Historian: 1–14\n2020: “Connecting the Dots: Rethinking Cartographies of Connectivity,” PLATFORM. https://www.platformspace.net/home/connecting-the-dots-rethinking-cartographies-of-connectivity\n2019: “Addressing Divergent Digital Literacies and Visualizing Data Uncertainty in Social Networks and the Ancient Greek Garrisons Project.” Classics@ 17. https://classics-at.chs.harvard.edu/classics17-horne/\n\n\n\n2021: Maps and infographics in Mostern Ruth, Yellow River: A Natural and Unnatural History Yale University Press.\n2020-2022: Sinai Manuscripts Digital Library. Data and Metadata Coordinator. Site development; Data and metadata development https://sinaimanuscripts.library.ucla.edu/\n2019-2020: World History Gazetteer. Data modeling, database design, data coordination. https://whgazetteer.org/\n2017-2022: Black Lunch Table Audio Archive, Digital Director. Site and database design and development. https://blacklunchtable.com/\n2017: Hierokles’ Synekdemos. Ancient World Mapping Center, University of North Carolina, Chapel Hill. Site and database design and development.\nhttp://awmc.unc.edu/awmc/applications/hierokles/\n2017: IAH Knowledge Network Map. Institute for the Arts and Humanities, University of North Carolina, Chapel Hill. Site and database design and development. https://iah-unc.github.io/knowledge-network/\n2017: with Talbert, Richard, Brian Turner, Jeffrey Becker, Ross Twele, and Gabriel Moss. Map of Asia Minor in the Second Century C.E., Ancient World Mapping Center, University of North Carolina, Chapel Hill. Cartographer and data coordinator. http://awmc.unc.edu/wordpress/blog/2017/02/22/wall-map-now-available-asia-minor-in-the-second-century-c-e/\n2015: with Sarah Bond and Paul Dilley. Terra Biblica and BAM Online Resources, University of Iowa. Designer and developer. http://bam.lib.uiowa.edu/\n2014: Strabo Digital Mapping Application in support of Roller, Duane W. 2014. Geography of Strabo: An English Translation, with Introduction and Notes. Cambridge: Cambridge University Press. Designer and developer.\n2014: AWMC Map Tiles A series of geographically accurate, publicly accessible map tiles of the Ancient World, which receive over 2.5 million views a year. Cartographer, designer, developer http://awmc.unc.edu/wordpress/tiles/\n2012-Present: Pleiades Project\nA peer-reviewed, community-built gazetteer and graph of ancient places\nhttp://pleiades.stoa.org/\nSee http://pleiades.stoa.org/credits\n2012: Antiquity À-la-carte A web-based GIS and interactive digital atlas of the Ancient World. http://awmc.unc.edu/wordpress/alacarte/\n2011: Tabula Peutinger Map in support of Talbert, Richard J. A., Tom Elliott, Nora Harris, and Martin Steinmann. 2010. Rome’s World: The Peutinger Map Reconsidered. Cambridge: Cambridge University Press. http://peutinger.atlantides.org/map-a/\n\n\n2013: Review of John Lendon. Song of Wrath: The Peloponnesian War Begins. The History Teacher, Volume 46, No. 2 (February 2013) p. 303-304\n2009: Review of John Hale. Lords of the Sea: The Epic Story of the Athenian Navy and the Birth of Democracy. The History Teacher, Volume 43, No. 1 (November 2009) p. 146- 147\n\n\n\n\n\n\n\n2021: “Mare Nostrum: Using Linked Open Data, Network Analysis and Historical GIS to Model Ancient Waters” in the panel Technologies and New Solutions. Roman Waters: Literature, Archaeology, and New Technologies, LMU Munich, September 16-17\n2020: “Mediterranean Pathways: GIS, Network Analysis, and the Ancient World” in the panel (Inter-)Regional Networks in Hellenistic Eurasia. 2020 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Washington, DC, January 2–5\n2019: “HGIS, Networks, and Numismatics” in the panel Geospatial Classics: Teaching and Research Applications of G.I.S. Technology. 2019 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, San Diego, California, January 3–6\n2018: “Using the new Antiquity À-la-carte 2.0 to create custom maps with data from Pleiades and the Ancient World Mapping Center” in the workshop Turning Spatial with Pleiades: Creating, Teaching, and Publishing Maps in Ancient Studies, 2018 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Boston, Massachusetts, January 4–7\n2017: “People, Places, and Time: Representing Entities In the Big Ancient Mediterranean Project” in Global Philology: Digital Infrastructure for Named Entities Data, Leipzig, January 11-13\n2017: “Make Your Own Map” in the workshop Ancient Maker Spaces: Digital Tools for Classical Scholarship, 2017 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Toronto, January 5–8\n2016: “Linked Data and the The Big Ancient Mediterranean”, Workshop on Digital Humanities, Carleton University, Ottawa, May 14-15\n\n\n\n2022: With Greg Janée, Rena Curty, Jon Jablonski, Kristi Liu, and Amanda Ho, “Incorporating Data Literacy Topics into Carpentries Lessons”, 2022 CarpentryCon, August 3\n2021: “Landscapes in Motion: Cartographies of Connectivity and the Place of Physical Geography in the Environmental and Spatial Humanities”, 2021 UC GIS Week, November 16-18\n2021: With Dawn Childress, “Linked Open Data in the Sinai Manuscripts Digital Library Project”, 2021 LD4 Conference on Linked Data, July 19-23\n2021: “Welcome to the world of geospatial Linked Open Data”, 2021 UC GIS Meetup, April 1\n2016: “Fuzzy Networks, Fuzzy Geography: Visualizing Complex Networks and Uncertain Data in the Big Ancient Mediterranean”, Linking the Big Ancient Mediterranean Conference, University of Iowa, June 6-8\n2016: with Sarah Bond and Paul Dilley, “BAM: Text, Networks, and GIS Mapping in the Big Ancient Mediterranean”, Mapping the Past: G.I.S. Approaches to Ancient History, University of North Carolina, Chapel Hill, April 8-9\n2015: with Sarah Bond and Paul Dilley, “Developing the Terra Biblica and BAM (“Big Ancient Mediterranean”) Online Resources” in the panel Digital Humanities and the Study of Patristics, Session 1, 17th International Conference on Patristic Studies, Oxford, August 10-14\n2013: “Beyond Maps as Images at the Ancient World Mapping Center”, Linked Ancient World Data Institute, Drew University Campus, May 30-June 1\n2013: “Mapping Antiquity À-la-carte: A GIS Interface of the Ancient World” at Word, Space, Time: Digital Perspectives on the Classical World, Digital Classics Association at SUNY Buffalo, April 5-6\n2012: “Mapping Antiquity À-la-carte” in the panel New Mapping Resources for Instructors and Students, 108th CAMWS Annual Meeting, Baton Rouge, Louisiana, March 28-31\n\n\n\n2024 (forthcoming): “A Network of Linked Places: Spatial Network Construction using Pleiades, World History Gazetteer, and GeoJSON”, Linked Pasts 10 / Linked Pasts Japan 1, National Institute of Informatics, Tokyo, Japan, Decembet 9 - 12\n2024: with Loreto Granados García, Paula. “Mary Jaharis Center for Byzantine Art and Culture Data Workshop”, Mary Jaharis Center for Byzantine Art and Culture, Hellenic College Holy Cross, MA, May 13 - 17\n2023: with Seifred, Becky. “Working with Maps: An Introduction to GIS, Spatial Data, and Geospatial Resources for Byzantinists”, Mary Jaharis Center for Byzantine Art and Culture, Hellenic College Holy Cross, MA, May 15 - 18\n2021: with Biswas, Paromita, Dawn Childress, Iman Dagher, and Erica Zhang. “Connecting Knowledge: Linked Open Data in Libraries”, UC Libraries Forum 2021, October 26 - 29\n2020: Levitan, Rebecca et. al. “The Digital Futures of Ancient Objects: Discussing Next Steps for Collaborative Digital Humanities Projects”, 2020 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Washington, DC, January 2–5\n2019: Grossner, Karl, Ryan Horne and Ruth Mostern “Linking Pasts with Place Names and Gazetteers”, ACH 2019 Conference, Pittsburgh, PA, July 23-26\n\n\n\n2015: “Draft Map of Hispania during the Second Century C.E.”, poster session, 116th Annual Meeting of the Archaeological Institute of America, New Orleans, January 8–11\n\n\n\n2023: Chair, UC GIS Week, November 13-17\n2019: Panel Organizer for Geospatial Classics: Teaching and Research Applications of G.I.S. Technology. 2019 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, San Diego, California, January 3–6\n2010: Planning Committee for Beyond Borders: Ancient Societies and their Intellectual Frontiers, The Ancient Borderlands International Graduate Student Conference, University of California, Santa Barbara\n\n\n\n2022: “How Not to Lie with Data: Trustworthy Data Storytelling”, UC Love Data Week, University of California, Santa Barbara, February 14\n2021: “A Borderland in Imperial Networks: Aeolis in the Hellenistic World”, Mapping Mobilities Session 3, University of Southern California, January 21\n2019: “Mediterranean Pathways: GIS, Network Analysis, and the Ancient World”, University of California, Santa Barbara, May 20\n2018: with Mostern, Ruth. “Digital Methods in Spatial History workshop”, in 2018 Globalizing World History Research Symposium, University of Pittsburgh, August 24–25\n2014: “New Pathways Through the Ancient World: HGIS, Linked Data, and the Web”, Wake Forrest Digital Humanities Kitchen, Wake Forrest University, October 24\n2014: “Creating a Picture of History: Maps, Data and Method at the Ancient World Mapping Center”, Keynote, UNC / King’s College Transatlantic Conference, UNC Chapel Hill, September 16\n2012: “Mapping Digital Prosopographies”, meeting of The California Consortium for the Study of Late Antiquity, University of California, Davis, October 5\n\n\n\n2024: “Digital Formats”, Vital Matters / Art, Devotion, Practice, UCLA Fowler Museum, October 16\n2022: “Shifting Cartographies: Geospatial Networks”, 2022 UCLA Global Humanisms Digital Humanities Forum, November 7\n2021: With Dawn Childress, “An Evolving Sinai Manuscripts Data Program”, 2021 UCLA Library Research Forum Program, March 23\n2014: “AWMC Research”, Poster Session, ITS Research Computing Symposium, UNC Chapel Hill, May 20\n2014: with Ross Twele “Mapping the Ancient Mediterranean in the Digital Age”, HGIS Carolina Student Showcase, UNC Chapel Hill, April 3\n2014: “AWMC Research”, Poster Session, University Research Day, UNC Chapel Hill, March 4\n2012: “Antiquity À-la-carte”, Innovative Use of GIS, UNC Chapel Hill, November 14\n\n\n\n2024: “Markdown, Zotero, and Quarto for Academic Writing and Publishing”, UCLA Office of Advanced Research Computing, October 7\n2024: “Introduction to Network Analysis Methodologies and Tools”, UCLA Office of Advanced Research Computing, April 19\n2023: “Introduction to Data Storytelling”, UCLA Office of Advanced Research Computing, June 27\n2023: “Introduction to Network Analysis Methodologies and Tools”, UCLA Office of Advanced Research Computing, April 14\n2022: “Introduction to QGIS”, UCLA Office of Advanced Research Computing, January 20\n2022: with Curty, Renata and Greg Janée “Using the DMP Tool”, UCSB Office of Research, May 20\n2022: “Introduction to Webscraping”, UCSB Library Carpentry Workshop, May 12-13\n2022: “Data Analysis and Visualization in Python”, UCSB Data Carpentry Workshop, April 19-21\n2022: with Curty, Renata “Data Storytelling for the Social Sciences and Humanities”, UCSB Research Data Services Workshop Series, April 27\n2022: with Curty, Renata “Intro to Digital Humanities and Digital Social Science”, UCSB Research Data Services Workshop Series, April 6\n2021: “Introduction to QGIS and Making a Map in the Humanities”, UCLA Library Research Workshop, January 14\n2020: “Introduction to Mapping and Digital Gazetteers for the Humanities”, UCLA Library Research Workshop, November 17\n2018: “Introduction to Network Analysis and Visualization”, University of Pittsburgh Library, October 12\n2018: “Introduction to QGIS”, University of Pittsburgh Library, September 28\n2017: “Introduction to Network Analysis and Visualization”, University of Pittsburgh Library, October 12\n\n\n\n\n2024: Co-author, AI Acceleration Grant, UCLA Office of Advanced Research Computing, $1,500\n2021: Co-author, Mellon Foundation Grant #2101-09956, for the Black Lunch Table Digital Archive (PI: Jina Valentine), $500,000\n2021: Co-author, NEH Digital Humanities Advancement Level III Grant #HAA-280677-21, for Sinai Manuscripts Data Portal Project (PIs: Virginia Steel and Dawn Childress), $325,000\n2020: Co-author, The Andy Warhol Foundation for the Visual Arts, for the Black Lunch Table (PI: Jina Valentine), $60,000\n2019: Digital Atlas Design Internship course selected as one of four University of Pittsburgh entries to the ACC Smithsonian Creativity and Innovation Festival, National Museum of American History, Washington, D.C, April 5-7\n2018: WikiConference North America 2018 Scholarship\n2018: NEH-Mellon Fellowship for Digital Publication #FEL-257341-18, $50,400\n2015: Co-author, Obermann Center for Advanced Studies Interdisciplinary Research Grant, University of Iowa\n2014: Holsenbeck Fund, University of North Carolina, Chapel Hill\n2013: Raymond Faherty Research Grant for Military History, University of North Carolina, Chapel Hill\n2013: George B. Tindall Graduate Fellowship for Summer Research, University of North Carolina, Chapel Hill\n2013: Semple Award, Classical Association of the Middle West and South\n2012: Wadell Fund, University of North Carolina Chapel Hill\n2012: Mowry Dissertation Fellowship, University of North Carolina Chapel Hill\n2011: Clein Fund, University of North Carolina Chapel Hill\n2009: Drake Fund, University of California, Santa Barbara\n\n\n\n\n\n2024: DH 150: Social Justice and GIS, Digital Humanities Program, Fall Quarter\n2024: DH 150: Social Justice and Network Analysis, Digital Humanities Program, Summer Quarter\n2024: DH 101: Introduction to Digital Humanities, Digital Humanities Program, Winter Quarter\n2023: DH 150: Social Justice and GIS, Digital Humanities Program, Spring Quarter\n2023: DH 131: Social Justice and GIS, Digital Humanities Program, Fall Quarter\n\n\n\n2019: Digital Atlas Design Internship, History Department, Spring Semester\n2018: Digital Atlas Design Internship, History Department, Fall Semester\n2018: Digital Atlas Design Internship, History Department, Spring Semester\n2017: Digital Atlas Design Internship, History Department, Fall Semester\n\n\n\n2017: Introduction To Historical Geographic Information Systems, Honors College, Spring Semester\n2016: Introduction To Social Network Analysis and Conspiracy Theories, Honors College, Fall Semester\n2015: Roman History, History Department, Summer Session II\n\n\n\n2013: History of Greece, History Department, Fall Semester\n2012: Roman History, History Department, Spring Semester\n2011: Ancient History, History Department, Fall Semester\n\n\n\n2010: Western Civilization: 1715 CE to Present, History Department, Spring Quarter\n2009: Introduction to the Middle East, Global and International Studies Program, Fall Quarter\n2009: World History: 7000 BCE-1000 CE, History Department, Spring Quarter\n2008: Introduction to the Middle East, Global and International Studies Program, Fall Quarter\n\n\n\n\nJavascript (including D3.js, Leaflet, OpenLayers), PHP, C++, C, Java, R, R studio, Python (including anaconda and jupyter notebooks), SQL (including mySQL, PostgreSQL, PostGIS), XML, RDF, Linux, Gephi, Drupal, Wordpress\n\n\n\n\n\n2022: Born-Digital and Digital Archives Working Group, UCSB Library\n\n\n\n2021-present: Development Advisory Board, World Historical Gazetteer\n2018: Advisory Board, Mediterranean Connectivity Initiative\n2018-2022: Vice Chairman of the Board, Black Lunch Table\n\n\n\n2022: Article Reviewer, International Journal on Digital Libraries\n2022: Panelist, NEH digital humanities advancement grant competition\n2021: Article Reviewer, International Journal of Humanities and Arts Computing\n2018: Panelist, NEH digital humanities advancement grant competition\n2018: Article Reviewer, Journal of Field Archaeology\n2014-2015: Co-Managing Editor, Pleiades Project (NEH Digital Implementation Grant Awarded, July 2015)\n2013-Present: Associate Editor, Pleiades Project\n\n\n\n2022-Present: Digital Humanities Mentor, Digital Ethics Futures Consortium\n\n\n\n\n2022: Certified Software Carpentries Instructor\n2022: Certified SCRUM Product Owner\n2020: Selected as a participant in the Linked Open Data – Libraries, Archives, Museums (LODLAM) Summit. The Getty Center, February 3-4.\n2018-2019: Selected as a participant in the Institute in Ancient Itineraries: The Digital Lives of Art History. King’s College, London, England and Swedish Institute at Athens, Athens, Greece.\n2013: Participant in the American School of Classical Studies at Athens Summer Session I, Athens, Greece\n2012: Participant with stipend in the Eric P. Newman Graduate Seminar in Numismatics, American Numismatic Society, New York, New York\n\n\n\nFrench: Intermediate reading\nGerman: Intermediate reading\nItalian: Intermediate reading\nAncient Greek: Research language\nLatin: Research language\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "cv.html#education",
    "href": "cv.html#education",
    "title": "CV",
    "section": "",
    "text": "August, 2015: Ph.D., History, University of North Carolina, Chapel Hill\nMay, 2010: M.A., History, University of California, Santa Barbara\nMay, 2005: B.A. / B.S., Dual major in History and Information Sciences and Technology, Pennsylvania State University"
  },
  {
    "objectID": "cv.html#professional-experience",
    "href": "cv.html#professional-experience",
    "title": "CV",
    "section": "",
    "text": "2022 - present: Digital Research Specialist, Office of Advanced Research Computing, University of California, Los Angeles\n2021 - 2022: Digital Humanities Research Facilitator, Research Data Services, University of California, Santa Barbara Library\n2020 - 2021: Sinai Manuscripts Digital Library Data/Metadata Coordinator, Digital Library Program, University of California, Los Angeles Digital Library Program\n2019 - 2020: Research Associate, World History Center, History Department, University of Pittsburgh\n2017 - 2019: Post-Doctoral Fellow, World History Center, History Department, University of Pittsburgh\n2015 - 2017: Post-Doctoral Fellow, the Carolina Digital Humanities Initiative, History Department, and the Institute for the Arts and Humanities, University of North Carolina, Chapel Hill\n2014 - 2015: Director, Ancient World Mapping Center, History Department, University of North Carolina, Chapel Hill\n2010 - 2014: Digital Director, Ancient World Mapping Center, History Department, University of North Carolina, Chapel Hill\n2008 - 2010: Teaching Assistant, University of California, Santa Barbara\n2005 - 2007: Software Engineer Associate, Lockheed Martin, Owego, NY\n(Developed optical character recognition software and web resources)"
  },
  {
    "objectID": "cv.html#publications",
    "href": "cv.html#publications",
    "title": "CV",
    "section": "",
    "text": "2020: Aeolian Alexanders: Economic, Material, and Social Networks in Antiquity Electronic publication supported by a NEH-Mellon Fellowship for Digital Publication. https://github.com/Aeolian-Alexanders\n\n\n\n2021: Bond, Sarah, Paul Dilley, and Ryan Horne (eds). Linked Open Data for the Ancient Mediterranean: Structures, Practices, Prospects. ISAW Papers 20. http://dlib.nyu.edu/awdl/isaw/isaw-papers/20/\n\n\n\n2022: Horne, Ryan and Ruth Mostern. “Landscapes in Motion: Cartographies of Connectivity and the Place of Physical Geography in the Environmental and Spatial Humanities” In Routledge Handbook of the Digital Environmental Humanities, ed. Luke Bergmann, Arlene Crampsie, Deborah Dixon, Steven Hartman, Robert Legg, Francis Ludlow, and Charlie Travis. Routledge. p. 470-489\n2021: Digital Approaches to the ‘Big Ancient Mediterranean.’” In Access and Control in Digital Humanities, ed. Shane Hawkins. Routledge. p. 78–95\n2021: Bond, Sarah, Paul Dilley, and Ryan Horne. “Introducing the Semantic Web and Linked Open Data,” in Bond, Sarah, Paul Dilley, and Ryan Horne (eds). Linked Open Data for the Ancient Mediterranean: Structures, Practices, Prospects. ISAW Papers 20. http://dlib.nyu.edu/awdl/isaw/isaw-papers/20-1/\n2021: “Applying Linked Open Data Standards,” in Bond, Sarah, Paul Dilley, and Ryan Horne (eds). Linked Open Data for the Ancient Mediterranean: Structures, Practices, Prospects. ISAW Papers 20. http://dlib.nyu.edu/awdl/isaw/isaw-papers/20-2/\n2021: Mostern, Ruth and Ryan Horne. “Tracking Yu: Developing a Data System for Yellow River History.” In Mostern, Ruth. Yellow River: A Natural and Unnatural History. Yale University Press. p. 247–266\n2020: “Mapping Power: Using HGIS and Linked Open Data to Study Ancient Greek Garrison Communities,” in Historical Geography, GIScience and Textual Analysis: Landscapes of Time and Place, ed. Charles Travis, Francis Ludlow, and Ferenc Gyuris. Springer. p. 213–227\n2014: “Beyond Maps as Images at the Ancient World Mapping Center.” in Elliott, Thomas, Sebastian Heath, and John Muccigrosso (eds). Current Practice in Linked Open Data for the Ancient World, ISAW Papers 7. http://dlib.nyu.edu/awdl/isaw/isaw-papers/7/horne/\n\n\n\n2022: Middle, Sarah, Ryan Horne, David A. McMeekin, Chiara Zuanni, and Alex Butterworth. “Geographies of Place in Digital Art History”, International Journal of Humanities and Arts Computing (IJHAC) 16, no.1: 94-109.\n2021: “Digital Tools and Ancient Empires: Using Network Analysis and Geographic Information Systems to Study Imperial Networks in Hellenistic Anatolia.” Journal of World History 32, no. 2: 321–43.\n2020: “Beyond Lists: Digital Gazetteers and Digital History,” The Historian: 1–14\n2020: “Connecting the Dots: Rethinking Cartographies of Connectivity,” PLATFORM. https://www.platformspace.net/home/connecting-the-dots-rethinking-cartographies-of-connectivity\n2019: “Addressing Divergent Digital Literacies and Visualizing Data Uncertainty in Social Networks and the Ancient Greek Garrisons Project.” Classics@ 17. https://classics-at.chs.harvard.edu/classics17-horne/\n\n\n\n2021: Maps and infographics in Mostern Ruth, Yellow River: A Natural and Unnatural History Yale University Press.\n2020-2022: Sinai Manuscripts Digital Library. Data and Metadata Coordinator. Site development; Data and metadata development https://sinaimanuscripts.library.ucla.edu/\n2019-2020: World History Gazetteer. Data modeling, database design, data coordination. https://whgazetteer.org/\n2017-2022: Black Lunch Table Audio Archive, Digital Director. Site and database design and development. https://blacklunchtable.com/\n2017: Hierokles’ Synekdemos. Ancient World Mapping Center, University of North Carolina, Chapel Hill. Site and database design and development.\nhttp://awmc.unc.edu/awmc/applications/hierokles/\n2017: IAH Knowledge Network Map. Institute for the Arts and Humanities, University of North Carolina, Chapel Hill. Site and database design and development. https://iah-unc.github.io/knowledge-network/\n2017: with Talbert, Richard, Brian Turner, Jeffrey Becker, Ross Twele, and Gabriel Moss. Map of Asia Minor in the Second Century C.E., Ancient World Mapping Center, University of North Carolina, Chapel Hill. Cartographer and data coordinator. http://awmc.unc.edu/wordpress/blog/2017/02/22/wall-map-now-available-asia-minor-in-the-second-century-c-e/\n2015: with Sarah Bond and Paul Dilley. Terra Biblica and BAM Online Resources, University of Iowa. Designer and developer. http://bam.lib.uiowa.edu/\n2014: Strabo Digital Mapping Application in support of Roller, Duane W. 2014. Geography of Strabo: An English Translation, with Introduction and Notes. Cambridge: Cambridge University Press. Designer and developer.\n2014: AWMC Map Tiles A series of geographically accurate, publicly accessible map tiles of the Ancient World, which receive over 2.5 million views a year. Cartographer, designer, developer http://awmc.unc.edu/wordpress/tiles/\n2012-Present: Pleiades Project\nA peer-reviewed, community-built gazetteer and graph of ancient places\nhttp://pleiades.stoa.org/\nSee http://pleiades.stoa.org/credits\n2012: Antiquity À-la-carte A web-based GIS and interactive digital atlas of the Ancient World. http://awmc.unc.edu/wordpress/alacarte/\n2011: Tabula Peutinger Map in support of Talbert, Richard J. A., Tom Elliott, Nora Harris, and Martin Steinmann. 2010. Rome’s World: The Peutinger Map Reconsidered. Cambridge: Cambridge University Press. http://peutinger.atlantides.org/map-a/\n\n\n2013: Review of John Lendon. Song of Wrath: The Peloponnesian War Begins. The History Teacher, Volume 46, No. 2 (February 2013) p. 303-304\n2009: Review of John Hale. Lords of the Sea: The Epic Story of the Athenian Navy and the Birth of Democracy. The History Teacher, Volume 43, No. 1 (November 2009) p. 146- 147"
  },
  {
    "objectID": "cv.html#conferences-and-talks",
    "href": "cv.html#conferences-and-talks",
    "title": "CV",
    "section": "",
    "text": "2021: “Mare Nostrum: Using Linked Open Data, Network Analysis and Historical GIS to Model Ancient Waters” in the panel Technologies and New Solutions. Roman Waters: Literature, Archaeology, and New Technologies, LMU Munich, September 16-17\n2020: “Mediterranean Pathways: GIS, Network Analysis, and the Ancient World” in the panel (Inter-)Regional Networks in Hellenistic Eurasia. 2020 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Washington, DC, January 2–5\n2019: “HGIS, Networks, and Numismatics” in the panel Geospatial Classics: Teaching and Research Applications of G.I.S. Technology. 2019 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, San Diego, California, January 3–6\n2018: “Using the new Antiquity À-la-carte 2.0 to create custom maps with data from Pleiades and the Ancient World Mapping Center” in the workshop Turning Spatial with Pleiades: Creating, Teaching, and Publishing Maps in Ancient Studies, 2018 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Boston, Massachusetts, January 4–7\n2017: “People, Places, and Time: Representing Entities In the Big Ancient Mediterranean Project” in Global Philology: Digital Infrastructure for Named Entities Data, Leipzig, January 11-13\n2017: “Make Your Own Map” in the workshop Ancient Maker Spaces: Digital Tools for Classical Scholarship, 2017 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Toronto, January 5–8\n2016: “Linked Data and the The Big Ancient Mediterranean”, Workshop on Digital Humanities, Carleton University, Ottawa, May 14-15\n\n\n\n2022: With Greg Janée, Rena Curty, Jon Jablonski, Kristi Liu, and Amanda Ho, “Incorporating Data Literacy Topics into Carpentries Lessons”, 2022 CarpentryCon, August 3\n2021: “Landscapes in Motion: Cartographies of Connectivity and the Place of Physical Geography in the Environmental and Spatial Humanities”, 2021 UC GIS Week, November 16-18\n2021: With Dawn Childress, “Linked Open Data in the Sinai Manuscripts Digital Library Project”, 2021 LD4 Conference on Linked Data, July 19-23\n2021: “Welcome to the world of geospatial Linked Open Data”, 2021 UC GIS Meetup, April 1\n2016: “Fuzzy Networks, Fuzzy Geography: Visualizing Complex Networks and Uncertain Data in the Big Ancient Mediterranean”, Linking the Big Ancient Mediterranean Conference, University of Iowa, June 6-8\n2016: with Sarah Bond and Paul Dilley, “BAM: Text, Networks, and GIS Mapping in the Big Ancient Mediterranean”, Mapping the Past: G.I.S. Approaches to Ancient History, University of North Carolina, Chapel Hill, April 8-9\n2015: with Sarah Bond and Paul Dilley, “Developing the Terra Biblica and BAM (“Big Ancient Mediterranean”) Online Resources” in the panel Digital Humanities and the Study of Patristics, Session 1, 17th International Conference on Patristic Studies, Oxford, August 10-14\n2013: “Beyond Maps as Images at the Ancient World Mapping Center”, Linked Ancient World Data Institute, Drew University Campus, May 30-June 1\n2013: “Mapping Antiquity À-la-carte: A GIS Interface of the Ancient World” at Word, Space, Time: Digital Perspectives on the Classical World, Digital Classics Association at SUNY Buffalo, April 5-6\n2012: “Mapping Antiquity À-la-carte” in the panel New Mapping Resources for Instructors and Students, 108th CAMWS Annual Meeting, Baton Rouge, Louisiana, March 28-31\n\n\n\n2024 (forthcoming): “A Network of Linked Places: Spatial Network Construction using Pleiades, World History Gazetteer, and GeoJSON”, Linked Pasts 10 / Linked Pasts Japan 1, National Institute of Informatics, Tokyo, Japan, Decembet 9 - 12\n2024: with Loreto Granados García, Paula. “Mary Jaharis Center for Byzantine Art and Culture Data Workshop”, Mary Jaharis Center for Byzantine Art and Culture, Hellenic College Holy Cross, MA, May 13 - 17\n2023: with Seifred, Becky. “Working with Maps: An Introduction to GIS, Spatial Data, and Geospatial Resources for Byzantinists”, Mary Jaharis Center for Byzantine Art and Culture, Hellenic College Holy Cross, MA, May 15 - 18\n2021: with Biswas, Paromita, Dawn Childress, Iman Dagher, and Erica Zhang. “Connecting Knowledge: Linked Open Data in Libraries”, UC Libraries Forum 2021, October 26 - 29\n2020: Levitan, Rebecca et. al. “The Digital Futures of Ancient Objects: Discussing Next Steps for Collaborative Digital Humanities Projects”, 2020 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, Washington, DC, January 2–5\n2019: Grossner, Karl, Ryan Horne and Ruth Mostern “Linking Pasts with Place Names and Gazetteers”, ACH 2019 Conference, Pittsburgh, PA, July 23-26\n\n\n\n2015: “Draft Map of Hispania during the Second Century C.E.”, poster session, 116th Annual Meeting of the Archaeological Institute of America, New Orleans, January 8–11\n\n\n\n2023: Chair, UC GIS Week, November 13-17\n2019: Panel Organizer for Geospatial Classics: Teaching and Research Applications of G.I.S. Technology. 2019 Joint Annual Meeting of the Archaeological Institute of America and the Society for Classical Studies, San Diego, California, January 3–6\n2010: Planning Committee for Beyond Borders: Ancient Societies and their Intellectual Frontiers, The Ancient Borderlands International Graduate Student Conference, University of California, Santa Barbara\n\n\n\n2022: “How Not to Lie with Data: Trustworthy Data Storytelling”, UC Love Data Week, University of California, Santa Barbara, February 14\n2021: “A Borderland in Imperial Networks: Aeolis in the Hellenistic World”, Mapping Mobilities Session 3, University of Southern California, January 21\n2019: “Mediterranean Pathways: GIS, Network Analysis, and the Ancient World”, University of California, Santa Barbara, May 20\n2018: with Mostern, Ruth. “Digital Methods in Spatial History workshop”, in 2018 Globalizing World History Research Symposium, University of Pittsburgh, August 24–25\n2014: “New Pathways Through the Ancient World: HGIS, Linked Data, and the Web”, Wake Forrest Digital Humanities Kitchen, Wake Forrest University, October 24\n2014: “Creating a Picture of History: Maps, Data and Method at the Ancient World Mapping Center”, Keynote, UNC / King’s College Transatlantic Conference, UNC Chapel Hill, September 16\n2012: “Mapping Digital Prosopographies”, meeting of The California Consortium for the Study of Late Antiquity, University of California, Davis, October 5\n\n\n\n2024: “Digital Formats”, Vital Matters / Art, Devotion, Practice, UCLA Fowler Museum, October 16\n2022: “Shifting Cartographies: Geospatial Networks”, 2022 UCLA Global Humanisms Digital Humanities Forum, November 7\n2021: With Dawn Childress, “An Evolving Sinai Manuscripts Data Program”, 2021 UCLA Library Research Forum Program, March 23\n2014: “AWMC Research”, Poster Session, ITS Research Computing Symposium, UNC Chapel Hill, May 20\n2014: with Ross Twele “Mapping the Ancient Mediterranean in the Digital Age”, HGIS Carolina Student Showcase, UNC Chapel Hill, April 3\n2014: “AWMC Research”, Poster Session, University Research Day, UNC Chapel Hill, March 4\n2012: “Antiquity À-la-carte”, Innovative Use of GIS, UNC Chapel Hill, November 14\n\n\n\n2024: “Markdown, Zotero, and Quarto for Academic Writing and Publishing”, UCLA Office of Advanced Research Computing, October 7\n2024: “Introduction to Network Analysis Methodologies and Tools”, UCLA Office of Advanced Research Computing, April 19\n2023: “Introduction to Data Storytelling”, UCLA Office of Advanced Research Computing, June 27\n2023: “Introduction to Network Analysis Methodologies and Tools”, UCLA Office of Advanced Research Computing, April 14\n2022: “Introduction to QGIS”, UCLA Office of Advanced Research Computing, January 20\n2022: with Curty, Renata and Greg Janée “Using the DMP Tool”, UCSB Office of Research, May 20\n2022: “Introduction to Webscraping”, UCSB Library Carpentry Workshop, May 12-13\n2022: “Data Analysis and Visualization in Python”, UCSB Data Carpentry Workshop, April 19-21\n2022: with Curty, Renata “Data Storytelling for the Social Sciences and Humanities”, UCSB Research Data Services Workshop Series, April 27\n2022: with Curty, Renata “Intro to Digital Humanities and Digital Social Science”, UCSB Research Data Services Workshop Series, April 6\n2021: “Introduction to QGIS and Making a Map in the Humanities”, UCLA Library Research Workshop, January 14\n2020: “Introduction to Mapping and Digital Gazetteers for the Humanities”, UCLA Library Research Workshop, November 17\n2018: “Introduction to Network Analysis and Visualization”, University of Pittsburgh Library, October 12\n2018: “Introduction to QGIS”, University of Pittsburgh Library, September 28\n2017: “Introduction to Network Analysis and Visualization”, University of Pittsburgh Library, October 12"
  },
  {
    "objectID": "cv.html#grants-fellowships-and-awards",
    "href": "cv.html#grants-fellowships-and-awards",
    "title": "CV",
    "section": "",
    "text": "2024: Co-author, AI Acceleration Grant, UCLA Office of Advanced Research Computing, $1,500\n2021: Co-author, Mellon Foundation Grant #2101-09956, for the Black Lunch Table Digital Archive (PI: Jina Valentine), $500,000\n2021: Co-author, NEH Digital Humanities Advancement Level III Grant #HAA-280677-21, for Sinai Manuscripts Data Portal Project (PIs: Virginia Steel and Dawn Childress), $325,000\n2020: Co-author, The Andy Warhol Foundation for the Visual Arts, for the Black Lunch Table (PI: Jina Valentine), $60,000\n2019: Digital Atlas Design Internship course selected as one of four University of Pittsburgh entries to the ACC Smithsonian Creativity and Innovation Festival, National Museum of American History, Washington, D.C, April 5-7\n2018: WikiConference North America 2018 Scholarship\n2018: NEH-Mellon Fellowship for Digital Publication #FEL-257341-18, $50,400\n2015: Co-author, Obermann Center for Advanced Studies Interdisciplinary Research Grant, University of Iowa\n2014: Holsenbeck Fund, University of North Carolina, Chapel Hill\n2013: Raymond Faherty Research Grant for Military History, University of North Carolina, Chapel Hill\n2013: George B. Tindall Graduate Fellowship for Summer Research, University of North Carolina, Chapel Hill\n2013: Semple Award, Classical Association of the Middle West and South\n2012: Wadell Fund, University of North Carolina Chapel Hill\n2012: Mowry Dissertation Fellowship, University of North Carolina Chapel Hill\n2011: Clein Fund, University of North Carolina Chapel Hill\n2009: Drake Fund, University of California, Santa Barbara"
  },
  {
    "objectID": "cv.html#teaching-experience",
    "href": "cv.html#teaching-experience",
    "title": "CV",
    "section": "",
    "text": "2024: DH 150: Social Justice and GIS, Digital Humanities Program, Fall Quarter\n2024: DH 150: Social Justice and Network Analysis, Digital Humanities Program, Summer Quarter\n2024: DH 101: Introduction to Digital Humanities, Digital Humanities Program, Winter Quarter\n2023: DH 150: Social Justice and GIS, Digital Humanities Program, Spring Quarter\n2023: DH 131: Social Justice and GIS, Digital Humanities Program, Fall Quarter\n\n\n\n2019: Digital Atlas Design Internship, History Department, Spring Semester\n2018: Digital Atlas Design Internship, History Department, Fall Semester\n2018: Digital Atlas Design Internship, History Department, Spring Semester\n2017: Digital Atlas Design Internship, History Department, Fall Semester\n\n\n\n2017: Introduction To Historical Geographic Information Systems, Honors College, Spring Semester\n2016: Introduction To Social Network Analysis and Conspiracy Theories, Honors College, Fall Semester\n2015: Roman History, History Department, Summer Session II\n\n\n\n2013: History of Greece, History Department, Fall Semester\n2012: Roman History, History Department, Spring Semester\n2011: Ancient History, History Department, Fall Semester\n\n\n\n2010: Western Civilization: 1715 CE to Present, History Department, Spring Quarter\n2009: Introduction to the Middle East, Global and International Studies Program, Fall Quarter\n2009: World History: 7000 BCE-1000 CE, History Department, Spring Quarter\n2008: Introduction to the Middle East, Global and International Studies Program, Fall Quarter"
  },
  {
    "objectID": "cv.html#software-competencies",
    "href": "cv.html#software-competencies",
    "title": "CV",
    "section": "",
    "text": "Javascript (including D3.js, Leaflet, OpenLayers), PHP, C++, C, Java, R, R studio, Python (including anaconda and jupyter notebooks), SQL (including mySQL, PostgreSQL, PostGIS), XML, RDF, Linux, Gephi, Drupal, Wordpress"
  },
  {
    "objectID": "cv.html#professional-service",
    "href": "cv.html#professional-service",
    "title": "CV",
    "section": "",
    "text": "2022: Born-Digital and Digital Archives Working Group, UCSB Library\n\n\n\n2021-present: Development Advisory Board, World Historical Gazetteer\n2018: Advisory Board, Mediterranean Connectivity Initiative\n2018-2022: Vice Chairman of the Board, Black Lunch Table\n\n\n\n2022: Article Reviewer, International Journal on Digital Libraries\n2022: Panelist, NEH digital humanities advancement grant competition\n2021: Article Reviewer, International Journal of Humanities and Arts Computing\n2018: Panelist, NEH digital humanities advancement grant competition\n2018: Article Reviewer, Journal of Field Archaeology\n2014-2015: Co-Managing Editor, Pleiades Project (NEH Digital Implementation Grant Awarded, July 2015)\n2013-Present: Associate Editor, Pleiades Project\n\n\n\n2022-Present: Digital Humanities Mentor, Digital Ethics Futures Consortium"
  },
  {
    "objectID": "cv.html#professional-development",
    "href": "cv.html#professional-development",
    "title": "CV",
    "section": "",
    "text": "2022: Certified Software Carpentries Instructor\n2022: Certified SCRUM Product Owner\n2020: Selected as a participant in the Linked Open Data – Libraries, Archives, Museums (LODLAM) Summit. The Getty Center, February 3-4.\n2018-2019: Selected as a participant in the Institute in Ancient Itineraries: The Digital Lives of Art History. King’s College, London, England and Swedish Institute at Athens, Athens, Greece.\n2013: Participant in the American School of Classical Studies at Athens Summer Session I, Athens, Greece\n2012: Participant with stipend in the Eric P. Newman Graduate Seminar in Numismatics, American Numismatic Society, New York, New York"
  },
  {
    "objectID": "cv.html#languages",
    "href": "cv.html#languages",
    "title": "CV",
    "section": "",
    "text": "French: Intermediate reading\nGerman: Intermediate reading\nItalian: Intermediate reading\nAncient Greek: Research language\nLatin: Research language"
  },
  {
    "objectID": "digital-portfolio.html",
    "href": "digital-portfolio.html",
    "title": "Digital Portfolio",
    "section": "",
    "text": "VSL Logo\n\n\n\n\nWorking in a collabiration between the Office of Advanced Research Computing and the Fowler Museum, I am the web developer and data designer / modeler for Visual and Sonic Landscapes of Muslims in Los Angeles, “…an effort to create a public space for self-representation and self-definition for Muslim Angelenos by Muslim Angelenos. A focus on community voices and ritual, music, murals, and other artworks as primary source materials defines this project.”\n  \n\n\n\n\n\n\nBLT Logo\n\n\n\n\nThis is an interdisciplinary project that studies cultural production and critical dialogue on racial issues. Started as a collaboration between UNC professors and working artists, Black Lunch Table brings together groups of African-American artists, academics, and activists throughout the United States. These groups have set dialogue topics, and the ensuing conversation is electronically archived and will be presented on an open access website. I led the design and development of new digital humanities methodologies and software for the project, including a combination of social network analysis and natural language processing to create innovative interfaces to catalog, search, and visualize the Black Lunch Table audio archives.\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "digital-portfolio.html#digital-gazetteers",
    "href": "digital-portfolio.html#digital-gazetteers",
    "title": "Digital Portfolio",
    "section": "Digital Gazetteers",
    "text": "Digital Gazetteers\n\n\n\n\nPleiades Project Image\n\n\n\nThe Pleiades Project\nI am an editor for the Pleiades Project, a gazetteer and graph offering authoritative data on over 36,000 sites in the ancient world. In addition to my content and editorial contributions, I have been working extensively on applying network analysis to the data set, creating new cartographical approaches to mapping place data, dealing with uncertainty, and creating new methods for exploring and representing the connectivity between places.\n\n\n\n\n\n\nWorld Historical Gazetteer Image\n\n\n\nWorld Historical Gazetteer\nAs a post-doc researcher I was part of the team that did initial planning, design, and development for the NEH winning World Historical Gazetteer, “…a platform for linking records about historical places, allowing people to make spatial connections across time and language.” With over 2 million place records, the WHG is one of the premier sources for historical place names and spatial information.\n\n\n\n\n\n\nBAM Project Image\n\n\n\nBig Ancient Mediterranean (BAM)\nBAM is an open-access project that integrates GIS tools, network analysis, and textual annotation/data mining capabilities in order to allow the exploration and visualization of ancient texts in new ways. BAM provides a modular framework which can be utilized by any number of different projects, and I have used the codebase to construct projects covering subjects ranging from the ancient world to today. I am also using BAM to explore methods to visualize and display data that is a mix of locatable and non-locatable entities. You can download the code here: https://github.com/Big-Ancient-Mediterranean/BAM."
  },
  {
    "objectID": "digital-portfolio.html#network-analysis",
    "href": "digital-portfolio.html#network-analysis",
    "title": "Digital Portfolio",
    "section": "Network Analysis",
    "text": "Network Analysis\n\n\n\n\n\n\nUNC Knowledge Networks\n This project, developed for the Institute for the Arts and Humanities at UNC Chapel Hill, identified previously unknown communities of common research interests at the university. It uses Library of Congress Subject Headings to categorize common faculty research interests, and deployed the Louvain method for community detection.\n\n\nWomen of Ancient History (WOAH)\n\nI created the initial functional prototype of WOAH. This project aims to provide accurate information on research interests and knowledge networks of women who study ancient history, in part to counteract the field’s prevalent gender imbalance found in academic conferences and publications. It is built on a crowd-sourced data set, and deployed the BAM software suite to highlight common research interests and the geographical distribution of women at institutes of higher education."
  },
  {
    "objectID": "digital-portfolio.html#web-applications",
    "href": "digital-portfolio.html#web-applications",
    "title": "Digital Portfolio",
    "section": "Web Applications",
    "text": "Web Applications\n\n\n\n\n\n\nAntiquity À-la-carte application\n\nThis is a web-based GIS interface and interactive digital atlas of the ancient world, featuring accurate historical, cultural, and geographical data produced by the AWMC in addition to the entire Pleiades Project feature set. The map is completely searchable with customizable features, allowing for the creation of any map covering Archaic Greece to Late Antiquity and beyond.  Click here or on the image above in order to launch the map application. This application works best with Firefox, Chrome, or Safari. The application is hosted on a custom installation of Mapserver, and is built with OpenLayers, GeoExt, and MapFish, with a PostGIS backend. For the use of À-la-carte in scholarship, see Kurt A. Raaflaub and John T. Ramsey, Reconstructing the Chronology of Caesar’s Gallic Wars, Histos 11, April 2017.\n\n\nSocial Networks and Greek Garrisons\n(http://awmc.unc.edu/awmc/applications/snagg/) This is a web-mapping application in support of my dissertation that catalogs all known ancient Greek garrisons (phrourai, phrouria, and phrouroi) and their commanders. There is a social network graph accompanying the map that is a work-in-progress; this will be finalized as a module that uses the BAM framework.\n\n\n\n\nStrabo Online\n\nMade to accompany  Duane W. Roller’s English translation of Strabo’s Geography ( ISBN: 9781107038257; e-book ISBN: 9781139950374), this is a seamless, interactive online map which is accessible for free here:  http://awmc.unc.edu/awmc/applications/strabo.  The application is built on the Antiquity À-la-carte interface, and plots the more than 3,000 locatable geographical and cultural features mentioned in the 17 books of this Greek source , stretching from Ireland to the Ganges delta and deep into north Africa. Like the Antiquity À-la-carte application, Strabo Online is hosted on a custom installation of Mapserver, and is built with OpenLayers, GeoExt, and MapFish, with a PostGIS backend and DataTables to assist with the presentation of the database.\n\n\nPeutinger Map A\n\nI finished a codebase originally begun by David O’Brien and Sean Gillies in support of Richard J.A. Talbert, Rome’s World: The Peutinger Map Reconsidered (Cambridge University Press, 2010). This viewer shows the Peutinger Map as a seamless whole, in color, with overlaid layers. The application is built with the Djatkoa JPEG 2000 Image Server and OpenLayers.\n\n\n\n\nThe AWMC API\n(http://awmc.unc.edu/api/)\n:** This allows the user access to all of the AWMC’s geographical information, both physical and cultural, using stable URIS. It is built with OpenLayers, PostGIS, and DataTables, with styling from WordPress and BuddyPress. It interfaces with the Pelagios Project using linked data principles, specifically through RDF. For a full explanation of how this was accomplished, please see this post.\n\n\nHierokles, Synekdemos\n\nThe Center’s single, interactive web map follows the text of Hierokles, Synekdemos in Ernest Honigmann’s edition (Brussels, 1939), and aims to supersede his four maps. With the Center’s Map Tiles as its base, the map marks all cities and regions which may identified and located with at least some confidence according to the Barrington Atlas and related publications listed below. Greek names are transliterated as in the Barrington Atlas (see Directory, p. vii). A full database lists all the place-names in the Synekdemos with references (thus including those that cannot be located and marked on the map). In addition, the text of Honigmann’s edition of the Synekdemos (and of the geographic work of George of Cyprus) is accessible via the Center’s Dropbox."
  },
  {
    "objectID": "digital-portfolio.html#geographic-information-systems",
    "href": "digital-portfolio.html#geographic-information-systems",
    "title": "Digital Portfolio",
    "section": "Geographic Information Systems",
    "text": "Geographic Information Systems\n\n\n\n\n\n\nAWMC Map tiles\n\nOffering the first (and at the time of this writing, only) geographically accurate base map of the ancient world, the AWMC tiles conform to the broad periodization presented in the Barrington Atlas, with different selectable water levels for the Archaic, Classical, Hellenistic, Roman, and Late Antique Periods. In addition, we also model inland water, rivers, and other geographical features as they appeared in antiquity. The base tiles are culturally agnostic, allowing them to be used to represent the physical environment of nearly any ancient society in the Mediterranean world.\nThese tiles are used by Pleiades, Harvard’s Digital Atlas of Roman and Medieval Civilizations, Stanford’s ORBIS application, and the Istituto di Studi sul Mediterraneo Antico, amongst others."
  },
  {
    "objectID": "digital-portfolio.html#print-maps",
    "href": "digital-portfolio.html#print-maps",
    "title": "Digital Portfolio",
    "section": "Print Maps",
    "text": "Print Maps\n\n\n\n\n\n\nHispania in the Second Century C.E**: At 1:750,000, scale and measuring 58.5 inches tall by 68 inches (149 by 173 cm), this map is a new addition to the AWMC’s class map series, and it will be offered as a stand-alone product. More information is available from the flier linked here. A Draft Map was displayed at the Poster Session of the AIA New Orleans meeting, Friday 9 January 2015, 10:45 am to 3: 00 pm.\n\n\nAsia Minor in the Second Century C.E**.: Like the map of Hispania, this map is produced at 1:750,000 scale, and is offered as a free download through the AWMC website. As a collaborative work, this map represents the current state of knowledge concerning Roman Anatolia, and was took several years to produce at the center. A draft of the map was presented by Richard Talbert at the ‘Roads and Routes in Anatolia’ conference organized by the British Institute at Ankara in March 2014.\n\n\n\nBenthos:  Currently in the Alpha stage, Benthos is a project of the Ancient World Mapping Center that aims to catalog and map the waters of the ancient Mediterranean basin, including both physical and cultural geography. The project will provide interactive maps of Mediterranean shipping networks, bathymetric data, and views of ancient coastlines. Currently the project is in a preliminary state, with a functional alpha version of the application based off of Antiquity À-la-carte.\nClick here or on the image above in order to launch the map application. This application works best with Firefox, Chrome, or Safari.\n\nPleiades Project: Although I do not work with the code of the site, I am a co-managing editor\nThrough my work at the Ancient World Mapping Center I participated in the creation of numerous print maps for research, classroom use, and traditional publications. Some highlights are below."
  },
  {
    "objectID": "posts/sna-wikipedia-and-the-hellenistic-world.html",
    "href": "posts/sna-wikipedia-and-the-hellenistic-world.html",
    "title": "SNA, Wikipedia, and the Hellenistic World",
    "section": "",
    "text": "Part of my work on the Big Ancient Mediterranean project involves creating a general software framework that can display social networks produced with Gephi, either as “stand alone” displays or integrated with geographic and textual information.\nI created this particular module, “Hellenistic” Royal Relationships, to highlight the “stand alone” social network analysis (SNA) capabilities of BAM, and to serve as the start of a more generalized Hellenistic prosopography. Some other, more specialized work has been done in this direction; notably Trismegistos Networks and the efforts of SNAP:DRGN to create data standards for describing prosopographies and linking to other projects. Eventually this module will take advantage of these efforts, and provide stable URIs for its own data.\nI envision this module serving several purposes. First, it provides an interesting visual representation of data contained within Wikipedia articles, including textual data that is not “linked” to other entries  and therefore not discoverable by automated means. It serves as a quick reference for familial relationships, and provides an entry point for further exploration and study. This project has created a “core” of relationships that can be further expanded by different projects. It also can function as a check on Wikipedia data; some of the relationships here are highly controversial, or could even be wrong.\nFor future development, the next steps are to add more data on the subjects, including birth / death / reigning dates and a time-line browser based on those dates. As mentioned above, more work needs to be done to take advantage of linked data projects, including linkages to Pleiades locations where appropriate, linkages to Nomisma IDs if the monarch minted coins, and the presentation of the underlying data in a format that is compatible with SNAP:DRGN. Finally, I would like to develop a method for the automatic discovery and extraction of relationships described in Wikipedia articles, which is an interesting, but difficult, problem.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/neh-mellon-fellowship-for-digital-publication-2017.html",
    "href": "posts/neh-mellon-fellowship-for-digital-publication-2017.html",
    "title": "NEH-Mellon Fellowship for Digital Publication",
    "section": "",
    "text": "neh_logo_horizontal_2c_c_outl_0\n\n\nI am pleased to announce that I received a NEH-Mellon Fellowship for Digital Publication to continue my work on digital die studies and Aeolian coin networks in the Hellenistic era. You can find a placeholder page for the project at http://aeolian-coins.org. The project’s code will be hosted at https://github.com/Aeolian-Alexanders.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/aeolian-alexanders-launches.html",
    "href": "posts/aeolian-alexanders-launches.html",
    "title": "Aeolian Alexanders Launches",
    "section": "",
    "text": "I am pleased to announce the launch of Aeolian Alexanders, a NEH-Mellon funded digital publication project. This combines social network analysis, historical geographic information systems, digital humanities, linked data, and numismatics. Check out the site, or take a twitter tour.\n\nThe project consists of a number of different elements, including\n\nA jupyter notebook that displays the narrative\nA jupyter notebook for a “lab book” for further exploration of geospatial networks\nThe project site that provides stable URIs and images for every coin and die in the study\nExperimental visual displays for die linkages\nA collection of files treating ancient empires as networks instead of polygons on a map\nThe full project database in SQLite\n\nCheck out the offerings on the project’s GitHub site.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/asia-minor-in-the-second-century-ce-a-new-wall-map-from-the-awmc.html",
    "href": "posts/asia-minor-in-the-second-century-ce-a-new-wall-map-from-the-awmc.html",
    "title": "Asia Minor in the Second Century CE: A New Wall Map From the Ancient World Mapping Center",
    "section": "",
    "text": "The Ancient World Mapping Center at UNC Chapel Hill has just released a 1:750,000 scale map of Roman Asia Minor in the Second Century CE under CC BY 4.0. Several years in the making, this map is a collaboration between several different directors of the center (including myself), domain experts, and other historians, and it represents the current state of knowledge about Roman Asia Minor in this period.\nIntended for class or research use, the map can be printed, distributed digitally, or remixed as desired. It is the same scale and general size as the AWMC’s other wall map offerings through Routledge, so if you are so inclined, you can add it to a “mega-map” of the Mediterranean World. Demand for the map was so high that dropbox suspended our public folder; you can e-mail the AWMC (awmc@unc.edu) for a new direct download link.\nAlthough this project is a static map of Asia Minor, the data behind the map can be found at the AWMC GitHub page. In a future post, I’ll write up how to use the AWMC geodata and the BAM framework to make an interactive version of this map which you can modify for your own needs.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/networks-geography-and-gephi-lots-of-promise-but-lots-of-work-to-be-done.html",
    "href": "posts/networks-geography-and-gephi-lots-of-promise-but-lots-of-work-to-be-done.html",
    "title": "Networks, Geography, and Gephi: Lots of Promise, but Lots of Work to be Done",
    "section": "",
    "text": "This post will outline some of my efforts to bring social networks into dialog with geography. Although I have found some interesting plugins and hacks, the results still leave something to be desired.\nTo provide some background: From my dissertation I have a nice, interactive map of all garrisons (phrourai, in orange), and garrison commanders (phrourarchoi, in white) from all of Greek sources up to the mid second century C.E. This is all nicely georeferenced, linked to other projects such as Pleiades and Pelagios, and serves its purpose pretty well. However, this provides the location and frequency of garrisons and commanders, and does not really show the social network that developed between commanders, monarchs, and communities. I could perhaps use a clustering strategy to create dynamic markers around specific points, but that seems to be a very unwieldy solution.\nStrictly speaking, by modeling people (phrourarchoi, monarchs) with places and abstract communities I am moving beyond a social network and instead looking at an information network, as I am interested in a number of different connections (social, geographic, ideological) that are not traditionally associated with social network analysis.\nThe first step to get all of my data into Gephi, assign different “types” to my nodes (in my case people, offices, places, phrourarchoi). I then created a network map, ran statistics, assigned the node size based on degree, and ran a force atlas layout. At the same time I also color coded the network based on type. This is all pretty basic Gephi use so far, and produced a perfectly serviceable network graph.\n[caption id=“attachment_186” align=“aligncenter” width=“300”] First graph. Pretty basic and serviceable.[/caption]\nNow it was time to experiment with different types of ranking. Betweenness centrality, or the measure of a node’s influence, led to an interesting difference in graphs:\n[caption id=“attachment_187” align=“aligncenter” width=“300”] Betweenness Graph. Note the increased importance of individuals.[/caption]\nHowever, this result is somewhat meaningless, as my graph covers a period from the 400s BCE to the 100s CE. Despite any of his wishes to the contrary, Ptolemy VIII did not live forever, yet he is the unquestioned central authority of this graph. All of the other Egyptian monarchs also score highly, underlining their importance in the communications and relationships between different phrourarchoi. This is an interesting yet hardly unsurprising finding - a good portion of the surviving data on phroruarchoi originates from Ptolemaic Egypt, which may inflate the relative importance of the dynasty in this kind of analysis. What this map does show is the enormous influence of individuals - most of whom were not phrourarchoi themselves.\nHowever, I am interested in garrisons as a sustained phenomena across several centuries, so I want to get back to the importance of location and geography on garrisons. In other words: Where are the most important locations for phrourarchoi, and how do those relate to one another?\nRunning an Eigenvector Centrality measurement produces a graph that somewhat mimics my original map, with physical locations, not people as the most significant authorities. This gives a better impression of what I am looking for - the centrality of a node relative to the whole network, which in my case privileges locations, which often serve as a bridge between different populations of nodes.\n[caption id=“attachment_189” align=“aligncenter” width=“300”] Eigenvector Centrality[/caption]\nTo me this is an interesting graph: It shows the importance of locations, while still highlighting important individuals. Now that I have this graph, I would love to place it on a map. I actually have coordinates for all of the locations, so a simple use of the Gephi GeoLayout plugin puts all of my identified places in a rough geographic layout.\n\n\n\nScreen Shot 2015-10-07 at 12.48.40 PM\n\n\nFrom here I simply fixed the location of the places, then ran some other layouts to try and make a coherent graph of people and offices that did not have a specific geographic value.The results were generally less than satisfying. The individuals in my dataset are not assigned coordinates because it would make little sense to do so - some phroruarchoi served in multiple locations, and almost all imperial phrourarchoi served outside their place of origin, were buried somewhere else, possibly lived in yet another location, etc.\n[caption id=“attachment_192” align=“alignleft” width=“300”] Force Atlas combined with GeoLayout[/caption]\n[caption id=“attachment_193” align=“alignright” width=“300”] Force atlas and Fruchterman-Reingold[/caption]\n[caption id=“attachment_195” align=“aligncenter” width=“300”] Adjusting the size of the nodes and running force atlas eventually produced  a result that looks more comprehensible, if a bit small.[/caption]\nFrom this step, I thought I would try out some Gephi plugins to push my data into a format I could drop onto a map. Only a very small percentage of my nodes actually contain geographic information, so the ExportToEarth plugin was not going to help. My first attempt at pushing out a shapefile using Export to SHP initially looked like a success in QGIS:\n[caption id=“attachment_196” align=“aligncenter” width=“300”] This looks promising…[/caption]\nSo, I decided to throw in some background, and that is when the trouble started. QGIS does a good job of transforming coordinates, but this was just messy (and not to mention wrong - there certainly were no phrourarchoi in Antarctica!)\n[caption id=“attachment_197” align=“aligncenter” width=“300”] Note how the nodes are now literally all over the map.[/caption]\nSo, what happened? If you do not have coordinates already explicitly assigned to your data, Export to SHP actually does not use “geographic” coordinates, and instead uses, in the words of the plugin, “fake geography – that is the current position of the nodes in the Gephi layout”. My thought that this position would line up with correct coordinates fromGeoLayout were false -Export to SHP treats the middle of the map as an origin point (instead of using whatever geographic data is present), and as such it does not match with any projection in QGIS.\nThis is a bit of a let down. It seems that all of mapping plugins in Gephi need for *ALL* of the nodes to have geographic information already baked in, or they will not export a geographically accurate map. This does make some sense, but it would be nice if you could use GeoLayout to place nodes with actual geographic data, then use force atlas or some other layout to produce a graph, and finally use the location of those nodes as coordinates. In other words, the location of nodes on the graph that have no actual geographic data of their own are located relative to nodes that do have geographic data. I tried the Sigmajs exporter, but the json object also does not use real coordinates, as seen in the fragment below ( lng and lat are the real-world coordinates, while x and y are used by SigmaJS):\n[code language=“javascript”]\n“label”:“Priene/‘Lince’?”, “x”:-22.65546226501465, “y”:32.66741943359375, “id”:“Pl_599905”, “attributes”:{ … “lng”:“27.297566084106442”, “lat”:“37.659724652604169”, …}, [/code]\nSo, is there a way around this?\nShort of writing a new plugin to do so, it looks like Gephi is simply missing the functionality of assigning geographic points to nodes that do not already have that information, then exporting that graph in a way that makes sense to mapping software. I could export an image and georeference that, but that will not provide the functionality I am looking for either.\nWhat I would like is for a graph produced by Gephi to use coordinates for nodes that have them, and make real world coordinates for nodes that do not. This map could then be placed on Leaflet / OpenLayers / whatever map, providing a level of interaction beyond a static image. As it is impracticable to duplicate the functionality (especially the statistical tools and layouts) of Gephi in a mapping application, this strikes me as something that would be very valuable to visualization and study.\nMy next idea is to see if R has something close to what I want, which I will detail in a future post.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/talk-at-ucsb-on-may-20th-mediterranean-pathways-gis-network-analysis-and-the-ancient-world.html",
    "href": "posts/talk-at-ucsb-on-may-20th-mediterranean-pathways-gis-network-analysis-and-the-ancient-world.html",
    "title": "Talk at UCSB on May 20th: Mediterranean Pathways: GIS, Network Analysis, and the Ancient World",
    "section": "",
    "text": "I will be delivering a talk May 20th at 12:15 at UCSB (location TBD) entitled Mediterranean Pathways: GIS, Network Analysis, and the Ancient World on some of the geospatial and network analysis I have been performing with my own research in conversation with ORBIS, Pleiades, Nomisma, and other linked open data sets. An abstract of the talk is below:\nWe live in a world of maps and networks. GPS enabled phones allow us to instantly locate ourselves on the earth’s surface, guide us to stores or restaurants, or announce to the world our location through social media. Likewise, programs like Google Earth and desktop Geographic Information Systems (GIS) have revolutionized our engagement with maps, map-making, and have challenged traditional notions of space and place.\nThe proliferation of GIS technologies and the “spatial turn” in digital humanities has also provided new avenues for challenging assumptions about the representations of past societies, the nature of empire, and the reach of imperial power. Despite their aesthetic beauty, traditional print maps, with clearly delineated static borders, often artificial naming conventions, and fixed viewpoints do not convey the complexity and uncertainty of the past.\nAncient societies and empires were far from static; they were networks of complex interactions and fierce contestation which unfolded in geographic space. This talk demonstrates how the use of new digital methodologies, gazetteers, and Linked Open Data (LOD) resources can be used to model and study these networks, and how new mapping techniques are transforming our understanding of ancient empire. Using the Attalid Kingdom as a guide, this talk examines the theory and practicalities of building an entity-relationship gazetteer and how to align it with LOD resources. It then addresses the construction of networks in desktop software, the impact of networks on cartography, and how new maps and digital models provided unique insights into the study of ancient Greek garrisons. The talk will then end with a brief overview of how Pleiades and other ancient world digital initiatives, including the Pelagios project’s Recogito platform, are developing new tools to enable the research and mapping of ancient networks.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/reporthate-whywereafraid-and-sna.html",
    "href": "posts/reporthate-whywereafraid-and-sna.html",
    "title": "#ReportHate, whywereafraid, and SNA",
    "section": "",
    "text": "With increasing social media incidents of election-related violence on twitter and social media, I decided to perform a quick network analysis of #ReportHate and whywereafraid (which, as of this writing, has removed its twitter link from its site). I am interested in examining the development of these online communities, if there are significant overlaps between them, and if there are opportunities for increased cooperation.\n[caption id=“attachment_689” align=“alignnone” width=“4937”] The main component of the #ReportHate network. Dr. Singh’s community is in purple, the SPLC is in green, and the alt-right grouping is in red.[/caption]\nFirst, I looked at each network in isolation. I started with the network formed around #ReportHate, which consists of 2,781 nodes, 4,217 edges and 79 components. (A quick network primer: nodes are users or hashtags, while edges represent users mentioning a hashtag or another user. Components are parts of the graph where every node can trace a path through a number of edges to another node, and degree is the number of edges connecting a node to other nodes).\nSurprisingly to me, the SPLC (@SPLCENTER) is not the node with the highest degree; that honor belongs to Dr. Simran Jeet Singh (@SIKHPROF), a professor of religion at Trinity University, despite SPLC’s approximate 9-1 advantage in followers (96.3 thousand to 10.7 thousand). It will be interesting to see if this disparity closes as more individuals are aware of the hashtag.\nThe top ten nodes by degree are dominated by two very different philosophies. @SIKHPROF, @SPLCENTER, @SHAUNKING, @AMYWESTERVELT, @TRUMPSWORLD2016, and @THIERISTAN are certainly aligned with progressive causes and appear to be supporters of the SPLC’s efforts to accurately report hate crimes. However, the next major node on the graph, @STOPHATECRIMEZ, appears to be an alt-right account (including an emoticon frog as a stand-in for Pepe the Frog), which tweets links to accounts of violence against Trump voters (dominated by links to YouTube) and refutations of violence committed by Trump supporters. The accounts that retweeted this account likewise seem to be dominated by alt-right and far right wing individuals, and the hashtag #HATECRIME is almost exclusively used by this group.\nMoving on from the alt-right component of the graph, it is apparent that there are several large clusters of SPLC supporters that as of yet do not have much interconnectivity. As this is a relatively new hashtag, I expect a growth of connections between clusters; if not, there is is an opportunity for the “central” nodes of each cluster to reach out to each other and establish a more robust online community. Another potential issue are nodes that are otherwise disconnected from the network; if these individuals are tweeting about incidents, it would be beneficial to reach out (virtually) and bring them into the larger #ReportHate network.\nUnlike the #ReportHate network, with a strong connected component, the whywereafraid network is far more dispersed and much smaller. There are 992 nodes and 938 edges, with 151 components. The node with the highest degree count is Patrick Kingsley (@PATRICKKINGSLEY), a foreign correspondent with the Guardian paper; his high degree is the result of his tweet linking to the whywereafraid tumblr account.\n[caption id=“attachment_699” align=“alignnone” width=“416”] The whywereafraid network[/caption]\nThe other two of the top three nodes, @ADAMPOWERS and @JAMIETWORKOWSKI, seem to be allied with the progressive movement. The next node with the highest degree is the official account of Donald Trump (@REALDONALDTRUMP). However, this is due to other twitter users castigating him over election violence.\nI then placed the networks together, to see if there was any overlap between the two growing communities. There are 26 users and 19 hashtags in common; when the entire network is placed in a graph, the node with the node with the highest degree of the 26 is @SHAUNKING, who is mentioned four times by other uses to bring his attention to whywereafraid. There are other tentative connections, but for the most part the two networks are very distinct, with little cross conversation.\n[caption id=“attachment_709” align=“alignnone” width=“3488”] The combined network. Edges that are from the #ReportHate data are in red, edges from the whywereafraid data are in blue.[/caption]\nThis represents a danger and an opportunity for the supporters of #ReportHate and whywereafraid. As the #ReportHate and whyweareafraid networks grow, there are likely to have increased links due to shared common interests, but there is the real possibility that many users will remain tied to their initial choice of hashtag, and not participate in the wider community or conversation. If nodes that are structurally important (a high betweenness centrality) in the #ReportHate graph, such as @SIKHPROF and @AMYWESTERVELT, could be brought into conversation with the major nodes of the whyweareafraid graph, then there is a good chance to merge the two networks, increasing awareness, mutual support, and an increased online presence.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/nodapl-twitter-analysis.html",
    "href": "posts/nodapl-twitter-analysis.html",
    "title": "#NoDAPL Twitter Analysis",
    "section": "",
    "text": "Introduction:\n[caption id=“attachment_512” align=“alignright” width=“327”] Map By Carl Sack[/caption]\nThe approximately 1,172 mile Dakota Access Pipeline1 has been highly controversial since its public unveiling in 2014.2 The Standing Rock Sioux and allied organizations took ultimately unsuccessful legal action to stop construction of the project, 3 while youth from the reservation began a social media campaign which gradually morphed into a larger movement with dozens of associated hashtags.4 I performed network analysis on #NODAPL, the most prominent of these hashtags on Twitter, between October 22 - 30, 2016. This revealed some interesting trends in the data, including the key role of alternative media, celebrities, and seemingly random twitter users holding the network together. Another surprising finding was the relatively minor role that republican candidate Donald Trump’s twitter account plays in the #NODAPL conversation, especially compared to the accounts of Barack Obama, Hilary Clinton, Bernie Sanders, and Dr. Jill Stein.\n[caption id=“attachment_560” align=“alignnone” width=“1024”] My Visualization of the #NODAPL network[/caption]\nPreliminary Network Analysis:\nDue to restrictions from the Twitter API and crashes / limitations from the software (see below), I do not have complete access to all Tweet traffic involving #NODAPL.5 I used the Twitter Archiving Google Sheet (TAGS) 6.16 to capture tweets that featured #NODAPL somewhere the tweet text. The resulting sheets were then imported into a database, then exported into an edges table for use in Gephi. For technical details, see the “Detailed Procedure” section below.\nBasic to any network analysis is the concept of nodes and edges. Nodes can represent people, places, things, ideas, etc – they are entities on the graph. In this case, nodes are twitter users and hashtags. Edges associate nodes in some manner; they can represent friendship, biological relationships, enmity, or anything else that links two nodes. For my analysis, edges are anytime a user includes a user name or hashtag in a tweet. For example, one of the most prominent users in this study, @RUTHHHOPKINS is represented as a node, with an edge created to the node #NODAPL every time she uses the hashtag in a tweet, like the example below:\nhttps://twitter.com/RuthHHopkins/status/794979004352700418\n# NODAPL itself was excluded as a node in this analysis, as every tweet and user would be directly connected to it. This network features 133,702 nodes linked by 630,393 edges.7 I used Gephi to identify communities of nodes that are strongly linked together, which are represented by different colors in the network visualization.8 In addition, I ran some basic network statistics, including measuring the degree of nodes (the number of edges between two individuals, hashtags, or individuals and hashtags) on the graph. In these measurements out-degree indicates that a node initiates a link to another node in the graph, which in this case means another user name or hashtag was mentioned in a text by the node in question. in-degree measures incoming edges, which indicates that a particular node is the subject of a twitter conversation.\nI first looked at the in-degree measurement. #STANDINGROCK was by far the node with the highest in-degree, indicating its popularity as a potential alternative hashtag to #NODAPL. @POTUS, the official twitter account of the President of the United States, was in second place, followed by #WATERISLIFE, @HILLARYCLINTON, @OFFICIALJADEN, @UR_NINJA, @SHAILENEWOODLEY, @MARKRUFFALO, and @RUTHHHOPKINS. In this list, only two nodes are not politicians, hashtags, or celebrities. @UR_Ninja is the official twitter account of Unicorn Riot9, a 501(c)3 nonprofit organization based in Minneapolis, Minnesota10 which has done extensive reporting on the Dakota Access Pipeline protests. @RUTHHHOPKINS is the twitter account of Ruth Hopkins, a Dakota/Lakota Sioux writer, journalist, and blogger. The high degree count on these nodes indicates that they may function as an information service, where their reporting on the situation is retweeted and mentioned by many other nodes in the network.\nThis measurement also revealed a marked difference between the in-degree and out-degree of nodes. The top 34 nodes by number of degrees are so dominated by in-degree connections that no node has an out-degree that contains more than 3.17% of its total edges. This reveals that such nodes are being “talked at”: they are mentioned in tweets, retweeted in large numbers, but by and large feature extremely limited further engagement with other Twitter users.\nA particular user group is indicative of this trend. Few politicians have used Twitter to actively engage with activists or to contribute to the dialogue surrounding the #NoDAPL movement. In some cases this is not surprising; the official twitter account of the President of the United States can scarcely be expected to contribute extensively to dialogue on twitter. Despite being the seventh highest degree node and an occupation of her Brooklyn campaign headquarters on October 27, 201611 @HILLARYCLINTON, the official account of Hillary Clinton, has likewise not responded to #NoDAPL conversations on twitter. The official account of Bernie Sanders, @SENSANDERS, has also not extensively engaged with #NODAPL. However, on October 31, 2016, which is outside of the bounds of my data set, his account did issue a series of tweets in support of the # NODAPL movement.12\nhttps://twitter.com/SenSanders/status/793196920613240840\nAnother account of a politician, Dr. Jill Stein (@DRJILLSTEIN), is twelfth on in-degree, but only has five outwardly directed edges. Despite active involvement at the protests leading to charges of criminal trespass and criminal mischief,13 Dr. Stein’s twitter account has barely engaged with other users, with the only mentions in this data set originating from a retweet that mentioned Hillary Clinton and Barack Obama.14 Interestingly, despite over 1,000 retweets (many of which were collected by this study), her tweet mentioning both Hillary Clinton and Donald Trump15 was not captured by the TAGS software.\nhttps://twitter.com/DrJillStein/status/792071109961285632\nPerhaps surprisingly for a major party candidate, the twitter handle of Donald Trump, @REALDONALDTRUMP, is an outlier on this list: he ranks at 112,160 with only 933 total mentions. Trump’s publicized investments and connections with the Dakota Access project16 and environmental positions, including discounting climate change,17 almost certainly makes him unlikely to be sympathetic, let alone an ally of the # NODAPL movement. Indeed, most of his mentions on the network are simply retweets of Dr. Jill Stein’s criticism against Donald Trump and Hillary Clinton’s lack of involvement in the pipeline issue.18\nDrilling down further into the data, I next looked at the nodes with the highest out-degree, which represents nodes who mentioned other users and hashtags. There were some interesting variations from the trends of in-degree nodes. Three users, @DEANLEH, @CANATIVEOBT, and @WMN4SRVL had in-degree and out-degree measurements that were no more than 20% divergent from each other. However, this does not mean that these nodes are engaged in extensive online conversations. These accounts all feature extensive retweets and linkages to different causes often associated with the progressive movement, including climate change awareness, opposition to institutional racism, feminism, and anti-corporatism. All three of these accounts seem to perform a function similar to news aggregation, as the majority of their mentions are retweets from other sources and are not extensive discussions with other users.\nAnother useful statistics, betweenness, measures the number of shortest paths (connections between any two nodes on the graph that may involve any number of additional nodes) that pass through a specific node.19 Nodes with a high betweenness are “central” in that they play a critical role in connecting (and therefore moving information) through the network. The single node with the highest betweenness is @UR_NINJA, which combined with its high degree ranking, suggests that the news service plays a critical role in bringing together individuals on the graph who are interested in social justice / progressive issues. Four other nodes in the top 25 betweenness list are likewise in the top 25 nodes by degree.\nThe remaing nodes are somewhat surprising. The twitter profile for second highest betweenness node, @TNPMR has a limited online footprint outside of Twitter, and does not seem to be involved in a leadership capacity in a social movement or media organization. Another important node in this measurement, @AMAZONMILLER, only scores 1638th in total degrees, yet still retains an important place in the network structure. Looking further at this data, I next examined at each individual user’s Twitter profile who scored in the top 25 for betweenness. I divided this list into people who seem to be primarily interested in progressive causes in general vs. those who expressed affinity for indigenous rights issues. The results were nearly evenly split, with a slight edge to the more general progressivists. However, only two of top ten nodes in the betweenness category focused primarily on indigenous issues, while the rest were concerned with progressivist issues more broadly. What this may indicate is that, as a whole, indigenous activists may face future difficulties in promoting their narrative outside of the more general progressive interests of the online community.\nFurther Observations:\nThese preliminary steps have also revealed some issues about data collection and curation. Twitter’s REST and streaming APIs are woefully inadequate for examining the whole data set. While Twitter provides, in theory, a representative sample of the data set, one of the powers of social network analysis is the discovery of weak ties and other network structures which are by definition not representative of the network as a whole. This can be frustrating for academic study of the network, and extremely detrimental to movements that depend on social media to transmit their messages. Groups can look at their own twitter histories, but the larger network structure, along with crucial weak ties, may be invisible to them.\nAlthough Twitter does provide mechanisms for obtaining the entire history of hashtag usage, the organic development of other hashtags which are not heavily watched from the beginning is almost certainly a cost-prohibitive proposition for social movements that are loosely organized, under-funded, and / or have limited computer infrastructure. It would be a significant benefit for such groups to gain access to the Twitter history of their movements, and be able to the evolution of the conversation on social media. As hashtag use can grow organically, with many different signifiers used for conversations, Twitter’s current pricing structure and data access model puts these groups at a severe disadvantage and hinders the identification and cultivation of allied communities and supporters.\nA less pressing, but nevertheless important, issue is access to Twitter’s archive by researchers. Unlike print material or traditional media, which may be tedious to analyze but are fully (and for the most part cheaply) accessible to interested parties, the complete set of tweets on a topic are impossible to study without significant funding. Even if a researcher could guess all of the hashtags that could emerge from a dynamic topic, the Twitter streaming API does not provide all relevant tweets. Such limitations make it challenging to use Twitter data in a pedagogical setting. Some of my students have expressed interest in conducting similar projects, but the need for constant downstream connections and the high cost of historical tweets have made all but the most superficial studies impossible. There needs to be a more cost-effective means for projects operating on a limited budget, students, and other academic uses of Twitter’s data.\nNext Steps:\nIn addition to the data set on #NoDAPL featured here, I have also compiled a number of hashtags and data in separate TAGS sheets which can be combined to see more of the network. I am currently running a python script to grab more tweet data from the streaming API, which should provide more tweets. After placing this data in the network and performing some basic sentiment analysis, I want to see if distinct communities have formed around different hashtags, and if those communities have noticeably different rhetorical strategies that correspond to the inclusion of certain hashtags. A long term goal is to secure funding to obtain the complete twitter archive of #NODAPL and related hashtags in order to perform a full social network and sentiment analysis. In addition, I would like to examine the twitter history of @UR_Ninja and other alternative news organizations to see if their followers form recognizable activist communities. As part of this analysis, I am especially interested to see how these communities change when news organization shifts their focus between causes (like #FERGUSON to #NODAPL), and to examine the interactions of these virtual communities with different social movements.\nTo overcome the issues I discovered with TAGS and TwitterStreamingImporter, I am currently running a python script (modeled after http://adilmoujahid.com/posts/2014/07/twitter-analytics/) that pulls in the full json object from Twitter’s streaming API for a number of hashtags related to #NODAPL. I think the best approach is to perform a weekly update of a “master” network that captures all of the data that I can dealing with #NODAPL, and then running statistics / etc from a filtered network in Gephi. I will be sure to post any additional developments here.\nDetailed Procedure:\nThe first difficulty in analyzing Twitter traffic is actually obtaining Twitter data. While Twitter does retain a historical archive of all tweets, this resource is currently inaccessible for academic research unless licensing fees are paid to an archival service such as GNIP. There is an indication that GNIP is aware of the power of Twitter analytics for academic research, and there are different pricing plans available,20 but as my project is currently in the exploratory phase, I am operating without any funding. As such, I needed an alternative.\nI first used TAGS to pull historical and incoming tweets into separate google sheets for each hashtag I was interested in. TAGS uses Twitter’s REST API, which limits search rates and results.21 I ran into rate limits rather quickly with my searches; in addition, my documents in google also hit their size and row limit. TAGS does not provide the entire result from the Twitter API: fields like place, retweeted (which indicates if a tweet was retweeted or not), and other useful fields are left off. Finally, I noticed that the text of tweets was often truncated; this made searching form complete user names, hashtags, and full text problematic. Although TAGS is a convent way to collect tweets, it can not possibly hope to represent the full network.\nDespite these imitations, TAGS can still provide some powerful insights with a little modification. After importing my TAGS documents into a postgresql database, I mined the tweet text for all user mentions and hashtags from individual twitter users, which formed the edges of my network. I then imported this into Gephi v.0.9.122, where I performed some basic network analysis and visualizations of the data.\nAfter this analysis, I decided that I needed to capture more tweets as they are issued. I used the TwitterStreamingImporter plugin for Gephi,23 which uses Twitter’s streaming API.24 The result is not all tweets that contain specified search terms, but is instead a representative sample that numbers up to 1% of global tweets. At ~ 300 -500 million tweets per day,25 the streaming api will return 3 – 5 million tweets on a given subject. For small data sets this may be sufficient, but it is impossible to tell how truly representative this sample is without the complete Twitter firehose.26\nUnlike TAGS, TwitterStreamingImporter requires a constant internet connection to compile tweets. This is impracticable if not impossible for individuals who use a single laptop or other machine between different locations. I also experienced some crashes while performing analytics and changing/ running the visualization layouts; anyone wishing to style twitter data using this technique may wish to save constantly and export different files for styling purposes. This plugin does a nice job of drawing edges between users, tweets, and hashtags, and specifies the type of edge (tweet, retweet, hashtag, etc), although I would still like some more detailed information. The code is freely accessible,27 so I may be able to fork the repository and create a new plugin that pulls in all the data that I am interested in (especially geolocations, time of the tweet, etc). However, I think simply using a python script on a persistent connection will be my next step in this analysis.\nNotes:\n1  LLC Dakota Access and United States Army Corps of Engineers, “Environmental Assessment: Dakota Access Pipeline Project, Crossings of Flowage Easements and Federal Lands” (U.S. Army Corps of Engineers, Omaha District, 2016), 8, http://purl.fdlp.gov/GPO/gpo74064.\n2  Further reading can be found at https://nycstandswithstandingrock.wordpress.com/standingrocksyllabus/, created by NYC Stands for Standing Rock committee, a self described group “…group of Indigenous scholars and activists, and settler/ POC supporters.” (https://nycstandswithstandingrock.wordpress.com/about/).\n3  A. B. C. News, “Court Denies Tribe’s Appeal to Block Dakota Access Pipeline,” ABC News, October 11, 2016, http://abcnews.go.com/US/court-denies-tribes-appeal-block-controversial-dakota-access/story?id=42700614.\n4  “Rezpect Our Water,” accessed November 6, 2016, http://rezpectourwater.com/; “Thousands Nationwide Show Solidarity with the Standing Rock Sioux and #NoDAPL,” Sierra Club, September 13, 2016, http://www.sierraclub.org/planet/2016/09/thousands-nationwide-show-solidarity-standing-rock-sioux-and-nodapl.\n5  n.b. Twitter is case insensitive, but all user names and hashtags are capitalized here.\n6  https://tags.hawksey.info/\n7  I used Gephi with the OpenOrd Layout to create the network visualization1 after modifying TAGS data in a postgresql database. Although the OpenOrd layout is intended for undirected graphs (see https://marketplace.gephi.org/plugin/openord-layout/), its ability to handle large datasets and limited computing resources made it an attractive choice for this investigation.\n8  The modularity for the graph is 0.414, with 862 communities detected. 32 of these communities had 100 or more nodes, and totaled 131,080 of the 133,702 total, which is 98.04% of the total.\n9  http://www.unicornriot.ninja/\n10  “About,” Unicorn Riot, accessed October 30, 2016, http://www.unicornriot.ninja/?page_id=372.\n11  The Root Staff, “#NoDAPL: Indigenous Youths Occupy Hillary Clinton’s Brooklyn, NY, Headquarters,” The Root, October 29, 2016, http://www.theroot.com/articles/news/2016/10/nodapl-indigenous-youth-occupy-hillary-clintons-brooklyn-headquarters/; “Indigenous Youth Occupy Hillary Clinton Campaign Headquarters to Demand She Take Stand on #DAPL,” Democracy Now!, accessed November 4, 2016, http://www.democracynow.org/2016/10/28/indigenous_youth_occupy_hillary_clinton_campaign.\n12  https://twitter.com/SenSanders/status/793196920613240840\n13  See https://www.facebook.com/MortonCountySD/photos/pcb.317649668587378/317649315254080/?type=3&theater for an image of the warrant\n14  https://twitter.com/NaomiAKlein/status/791756857958203392\n15  https://twitter.com/DrJillStein/status/792071109961285632\n16  Oliver Milman, “Dakota Access Pipeline Company and Donald Trump Have Close Financial Ties,” The Guardian, October 26, 2016, sec. US news, https://www.theguardian.com/us-news/2016/oct/26/donald-trump-dakota-access-pipeline-investment-energy-transfer-partners; “The Latest: Trump Holds Dakota Access Pipeline Company Stock,” US News & World Report, accessed November 4, 2016, http://www.usnews.com/news/us/articles/2016-10-26/the-latest-pipeline-protesters-think-their-removal-imminent.\n17  “Did Trump Say Climate Change Was a Chinese Hoax?,” _@politifact_, accessed November 4, 2016, http://www.politifact.com/truth-o-meter/statements/2016/jun/03/hillary-clinton/yes-donald-trump-did-call-climate-change-chinese-h/.\n18  https://twitter.com/DrJillStein/status/792071109961285632\n19  I performed Eigenvector analysis on the data set, but there was little deviation in the top ranked nodes from ranking by total degree.\n20  https://gnip.com/academic/\n21  https://dev.twitter.com/rest/public/search\n22  https://gephi.org/\n23  https://gephi.org/plugins/#/plugin/twitter-streaming-importer\n24  https://dev.twitter.com/streaming/overview\n25  Jim Edwards, “Leaked Twitter API Data Shows the Number of Tweets Is in Serious Decline,” Business Insider, accessed November 2, 2016, http://www.businessinsider.com/tweets-on-twitter-is-in-serious-decline-2016-2; “Twitter Usage Statistics - Internet Live Stats,” accessed November 2, 2016, http://www.internetlivestats.com/twitter-statistics/#sources.\n26  Research on the representative accuracy of Twitter’s API has been mixed; see Fred Morstatter et al., “Is the Sample Good Enough? Comparing Data from Twitter’s Streaming API with Twitter’s Firehose,” arXiv Preprint arXiv:1306.5204, 2013; Fred Morstatter, Jürgen Pfeffer, and Huan Liu, “When Is It Biased?: Assessing the Representativeness of Twitter’s Streaming API,” in Proceedings of the 23rd International Conference on World Wide Web (New York, NY: ACM, 2014).\n27  https://github.com/totetmatt/gephi-plugins/tree/twitter\nBibliography\n“A Pipeline Fight and America’s Dark Past.” The New Yorker, September 6, 2016. http://www.newyorker.com/news/daily-comment/a-pipeline-fight-and-americas-dark-past.\n“About.” NYC Stands with Standing Rock, September 13, 2016. https://nycstandswithstandingrock.wordpress.com/about/.\n“About.” Unicorn Riot. Accessed October 30, 2016. http://www.unicornriot.ninja/?page_id=372.\n“Appeals Court Halts Dakota Access Pipeline Work Pending Hearing.” Indianz. Accessed November 6, 2016. http://www.indianz.com/News/2016/09/16/appeals-court-halts-dakota-access-pipeli.asp.\nCNN, Marlena Baldacci, Emanuella Grinberg and Holly Yan. “Dakota Access Pipeline: Police Remove Protesters.” CNN. Accessed November 6, 2016. http://www.cnn.com/2016/10/27/us/dakota-access-pipeline-protests/index.html.\nDakota Access, LLC, and United States Army Corps of Engineers. “Environmental Assessment: Dakota Access Pipeline Project, Crossings of Flowage Easements and Federal Lands.” U.S. Army Corps of Engineers, Omaha District, 2016. http://purl.fdlp.gov/GPO/gpo74064.\n“Dakota Access Pipeline.” Accessed November 6, 2016. http://www.daplpipelinefacts.com/.\n“Dakota Access Pipeline: Overview.” Accessed November 6, 2016. http://www.daplpipelinefacts.com/about/overview.html.\n“Did Trump Say Climate Change Was a Chinese Hoax?” _@politifact_. Accessed November 4, 2016. http://www.politifact.com/truth-o-meter/statements/2016/jun/03/hillary-clinton/yes-donald-trump-did-call-climate-change-chinese-h/.\nEdwards, Jim. “Leaked Twitter API Data Shows the Number of Tweets Is in Serious Decline.” Business Insider. Accessed November 2, 2016. http://www.businessinsider.com/tweets-on-twitter-is-in-serious-decline-2016-2.\nHealy, Jack. “From 280 Tribes, a Protest on the Plains.” The New York Times, September 11, 2016. http://www.nytimes.com/interactive/2016/09/12/us/12tribes.html.\n“Indigenous Youth Occupy Hillary Clinton Campaign Headquarters to Demand She Take Stand on #DAPL.” Democracy Now! Accessed November 4, 2016. http://www.democracynow.org/2016/10/28/indigenous_youth_occupy_hillary_clinton_campaign.\n“Judge Rules That Construction Can Proceed On Dakota Access Pipeline.” NPR.org. Accessed November 6, 2016. http://www.npr.org/sections/thetwo-way/2016/09/09/493280504/judge-rules-that-construction-can-proceed-on-dakota-access-pipeline.\n“Life in the Native American Oil Protest Camps.” BBC News, September 2, 2016, sec. US & Canada. http://www.bbc.com/news/world-us-canada-37249617.\nMcCausland, Phil. “More Than 80 Dakota Pipeline Protesters Arrested, Some Pepper Sprayed.” NBC News, October 23, 2016. http://www.nbcnews.com/news/us-news/more-80-dakota-access-pipeline-protesters-arrested-some-pepper-sprayed-n671281.\nMcCleary, Mike. “As Standing Rock Protesters Face Down Armored Trucks, the World Watches on Facebook.” WIRED. Accessed October 30, 2016. https://www.wired.com/2016/10/standing-rock-protesters-face-police-world-watches-facebook/.\nMilman, Oliver. “Dakota Access Pipeline Company and Donald Trump Have Close Financial Ties.” The Guardian, October 26, 2016, sec. US news. https://www.theguardian.com/us-news/2016/oct/26/donald-trump-dakota-access-pipeline-investment-energy-transfer-partners.\nMorstatter, Fred, Jürgen Pfeffer, and Huan Liu. “When Is It Biased?: Assessing the Representativeness of Twitter’s Streaming API.” In Proceedings of the 23rd International Conference on World Wide Web. New York, NY: ACM, 2014.\nMorstatter, Fred, Jürgen Pfeffer, Huan Liu, and Kathleen M Carley. “Is the Sample Good Enough? Comparing Data from Twitter’s Streaming API with Twitter’s Firehose.” arXiv Preprint arXiv:1306.5204, 2013.\nNews, A. B. C. “Court Denies Tribe’s Appeal to Block Dakota Access Pipeline.” ABC News, October 11, 2016. http://abcnews.go.com/US/court-denies-tribes-appeal-block-controversial-dakota-access/story?id=42700614.\n———. “Timeline of the Dakota Access Pipeline Protests.” ABC News, October 31, 2016. http://abcnews.go.com/US/timeline-dakota-access-pipeline-protests/story?id=43131355.\n“Rezpect Our Water.” Accessed November 6, 2016. http://rezpectourwater.com/.\nStaff, The Root. “#NoDAPL: Indigenous Youths Occupy Hillary Clinton’s Brooklyn, NY, Headquarters.” The Root, October 29, 2016. http://www.theroot.com/articles/news/2016/10/nodapl-indigenous-youth-occupy-hillary-clintons-brooklyn-headquarters/.\n“The Digital Transition: How the Presidential Transition Works in the Social Media Age.” Whitehouse.gov, October 31, 2016. https://www.whitehouse.gov/blog/2016/10/31/digital-transition-how-presidential-transition-works-social-media-age.\n“The Latest: Trump Holds Dakota Access Pipeline Company Stock.” US News & World Report. Accessed November 4, 2016. http://www.usnews.com/news/us/articles/2016-10-26/the-latest-pipeline-protesters-think-their-removal-imminent.\n“Thousands Nationwide Show Solidarity with the Standing Rock Sioux and #NoDAPL.” Sierra Club, September 13, 2016. http://www.sierraclub.org/planet/2016/09/thousands-nationwide-show-solidarity-standing-rock-sioux-and-nodapl.\n“Twitter Usage Statistics - Internet Live Stats.” Accessed November 2, 2016. http://www.internetlivestats.com/twitter-statistics/#sources.\nWilliams, Weston. “Standing Rock Protests Escalate, as Tribe Calls for DOJ to Investigate.” Christian Science Monitor, October 24, 2016. http://www.csmonitor.com/USA/Justice/2016/1024/Standing-Rock-protests-escalate-as-tribe-calls-for-DOJ-to-investigate.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/reflections-on-the-bam-conference.html",
    "href": "posts/reflections-on-the-bam-conference.html",
    "title": "Reflections on the BAM Conference",
    "section": "",
    "text": "I had the absolute privilege of attending the Big Ancient Mediterranean Conference (#BAM2016) this week. The remarkable projects, enthusiasm for all things digital, and congenial atmosphere was inspiring. Now that the conference has ended, I think it is a good time to organize my thoughts, and perhaps point out some of the common themes that particularly struck me.\n\nOur projects are ready talk to each other. This was one of the most exciting revelations of the conference. Many of the digital humanities projects and initiatives represented here not only offer their data in downloadable format (.csv files, JSON dumps, etc), but also feature feature-rich APIs. Even if we are not quite yet to the point where we are using the same meta-data / data standards (more on that later), the use of APIs with permanent URIs allows our data sets to meaningfully interact. The work of Pelagios creates an excellent medium to facilitate such communication, and opens up our data to initiatives that are not limited to studies of the ancient world.\nUsers, users, users, users. We had some spirited and fascinating debate about who the audience is for digital humanities projects, and if it is even possible to create an application that can be effectively used by different audiences (experts, the general public, grad students, etc). I fall squarely on the side of the idea that we engage with multiple audiences by the very nature of a freely-accessible online platform, but our debate revealed a fundamental design question that is often not explicitly addressed: Exactly *who* is a digital humanities project for? Although I may differ with the voices questioning the multi-audience approach, I certainly agree with the position that we need increased usability studies and more robust user information. It is not enough for us to create DH projects that answer our individual questions for ourselves – we need to understand how to communicate with an audience which is used to the visual literacies of web and is less familiar with the conventions of scholarly communication derived from a print medium. The sample edition of Calpurnius from the Digital Latin Library (http://digitallatin.github.io/viewer/editio-2.0.html) is a great model - it captures the information of a textual apparatus free of technical jargon, rendering critical information to a wider audience without a loss of scholarly rigor.\nUncertainty. A corollary to the discussion around users is the question of representing uncertainty. There was an interesting question of why we should recognize fuzzy data at all: if an application is directed solely at an academic audience, is it not correct to assume that our users implicitly know that any data or representation of the ancient world is somewhat problematic, and therefore have no problem consuming visual representations that ignore the idea of uncertainty entirely? As I think that our projects need to communicate with non-academic audiences (and indeed academics who may not be as familiar with the inherent uncertainty of the ancient world), I see a very real need to represent the imprecision and uncertainty of our data. Almost all of the projects at BAM grappled with fuzzy data, whether that was geo-spatial (location, assignment to a place), textual (uncertain letter forms, unclear manuscript tradition), or interpretive (multiple archaeological reconstructions, the placement of garrison soldiers at a specific community). Almost every project dealt with uncertainty in a way that reflected the scholarly tradition of their subject area, like placing notes in an apparatus, or describing fuzzy data through text. I see a critical need to establish a common meta-data vocabulary that can, at the very least, alert users (both human and computational) to the presence of uncertainty in our work. I also see room for a common visual literacy for representing uncertainty in maps, social networks, or other visualizations, which is a far more complex issue.\nMetadata and documentation. For example, even if it proves impossible / impractical / or undesirable to create a common visual literacy surrounding uncertainty, we need to implement a common way of indicating and describing fuzzy data that can be computationally consumed. This returns to my first point: our projects can now talk to each other through computational agents, but we must agree on the vocabulary governing that conversation. Alignment with Pelagios will help in that regard, but I think more attention needs to be paid at all levels of DH projects to metadata standards. For DH projects in the ancient world, the ontology for Linked Ancient World Data offered by LAWD (https://github.com/lawdi/LAWD) should be a staring point.\n\nMuch like the slow, often tedious process of generating metadata, creating documentation for DH projects is often overlooked. From comments in code to capturing the design decisions and the entire creative process, DH documentation needs to go beyond the narrative of the research question and capture the entire creative, intellectual, and industrial process of a DH project. The suggestion to look to the hard sciences foe guidance in this process is a fruitful place to start.\n\nThe use of open-source repositories and the continued importance of institutional support. Most of the projects at BAM had a presence at GitHub, and there was some very interesting discussion around the practicality and usefulness of a non-profit, academically oriented alternative. This debate had as a background the reality that GitHub and other free services are currently a critical component of our work, as many DH projects operate on a shoe-string budget and are dependent on largess from an institution or grants. Such funding is often uncertain; Pleaides, one of the most exemplary projects at BAM, has a 50% success rate at securing NEH funding. For smaller projects this rate may be even lower; some participants indicated that the reward to work ratio of grant applications is not attractive for smaller projects.\n\nThere is some good news though, as many institutions have expressed growing interest in the digital humanities as a field. As a digital humanities community we need to build on this interest with a push for institutional backing. The University of Iowa clearly demonstrated the excellent outcomes of a group that is both dedicated to digital humanities and able to provide hosting, archiving, and other technical support.\n\nThe continued need for face-to-face gatherings. While we have many electronic forums for communication (Twitter, Slack, IRC, site forums, etc), there is still something special that happens when DH scholars are brought together for several days, freed of other distractions, and think about the same issues as a group. For me, the headspace of a conference is entirely different than using Skype in my office; my other projects and papers are out of sight, (largely) out of mind, and my focus is squarely on the discussion.\nRelease the tweets. One place where documentation is somewhat overlooked is at conferences like BAM. Many conferences generate an end-product like proceedings, which while valuable, can not capture the conversation that surrounds each presentation. The incredible use of twitter by BAM attendees, and the use of storify to capture those tweets, can serve as a model for other conference proceedings. Conference organizers should establish an “official” twitter tag, advertise it widely on social media, and ensure that a conference venue offers free wifi-access to the attendees. This expands out the reach of the conference in real-time to attendees and remote presenters who would otherwise be unable to participate in the conversation. A critical component to this is also archiving – for BAM, the use of storify (part 1, part 2) and the support of Iowa libraries ensures that there is a searchable account that can be referenced of the conference and the wider conversation it sparked.\n\nThe BAM conference generated a lot of intriguing conversation and displayed a host of excellent projects. If this kind of interest, scholarship, and congeniality can be maintained, the future of DH is bright indeed.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/gephi-conspiracies-and-sna-in-the-classroom-midterm-thoughts.html",
    "href": "posts/gephi-conspiracies-and-sna-in-the-classroom-midterm-thoughts.html",
    "title": "Gephi, Conspiracies, and SNA in the Classroom: Midterm Thoughts",
    "section": "",
    "text": "Image from https://gephi.org/images/screenshots/layout2.png\nThis semester I designed a class, Introduction to Social Networks and Conspiracy Theories, that makes extensive use of Gephi along with the downloadable version of Networks, Crowds, and Markets: Reasoning About a Highly Connected World by David Easley and Jon Kleinberg. Readings on real conspiracies and conspiracy theories were compiled by myself into a course packet, and cover Ancient Athens, the assassination of Philip II, Knights Templar, the Gunpowder plot, the French Revolution, and conspiracy theories in the United States from the revolution to the present. In short, this class uses social network analysis to study paranoia from Plato to NATO.\nKey to this class is the understanding and use of SNA software. I chose Gephi as it has a forgiving learning curve for creating networks and conducting basic analysis, and its cross platform capabilities were required as I do not have access to a computer lab for the class. The other deciding factor was the ease of exporting Gephi files (through the use of the excellent Sigmajs exporter) to the web, as the students will produce a number of publicly available network visualizations, in addition to a written report, for their final project.\nGephi has shown its usefulness to the class. The ability to very quickly take .csv files and make meaningful network diagrams impressed the students, and showing network filtering in real-time is a powerful way to show conceptually how eliminating bridges and key nodes can throw a network into confusion. Some other positive points:\nGephi’s GUI vs. command line tools For my students, using a GUI has been a far better choice than a command-line or text driven interface. While the Gephi GUI can sometimes do strange things (like eliminate buttons or workspaces), on the whole its basic functionality is relatively intuitive. After a few demonstrations in the basics, the students have grasped how to create a network from spreadsheet data.\nReal-time rendering Keeping the various layouts running while filtering / changing elements of the network (especially the stand-by force atlas) powerfully illustrates many network concepts. It is also a very cheap (in time and effort!) method to create animated networks for the class.\nEase of stats While some of the statistics I would like to see are not in the core of Gephi, the ones that are present are excellent. The students, after learning about the math and logic behind various network statistics, were quite relieved to discover how quickly Gephi can compute centrality, density, and degree measurements.\nStyling After spending some time going over the interface, the ease of selecting different attributes and measurements for node styling is something that really captured the student’s attention. I anticipate a flood of very interesting network diagrams for their final projects based on different styling / visualization choices, which is an excellent way for students to support their arguments.\nCreating diagrams for the course Using Gephi to create network diagrams for the conspiracy portion of the course is a very straightforward process, and the excellent export capabilities ensure that all of the networks I share look very professional.\nWhile Gephi is an excellent piece of software, extensive use in the classroom has revealed some issues and missing features that do present a source of frustration for the class.\nJava can be difficult Supporting multiple operating systems with different Java installs on student laptops is an exercise in frustration. A class that uses Gephi extensively MUST have a supported computer lab, at the very least so that Java problems can be addressed and fixed for everyone at the same time in the same way. I am running my course without this, and I can attest that much class time has been wasted trying to troubleshoot Java and install issues on different OS / JVM combinations.\nGephi is not very fault tolerant  Data, at least in the humanities, is often messy, malformed, and non standards-compliant. I was stymied in class due to one character causing an issue in a data set that we found online - while text programs and Excel / OpenOffice handled the file gracefully, it blew up on Gephi.\nMany of the concepts discussed in SNA texts can not be easily seen in Gephi Concepts like triadic closure are somewhat difficult to capture, but there is nothing in Gephi to identify triads. It can compute the total number, but this is less useful for showing students where the triads are in a graph. I could also not find a way to view cliques, or to identify bridges programatically. Network balance is also something that is not readily apparent in Gephi.\nFiltering can be difficult While there are some powerful filtering features in Gephi, the class has had a difficult time conceptualizing their use and using them to their full potential. A more intuitive interface may solve some of these problems.\nSome features are Broken Embeddedness is not a core feature for Gephi, and the plugin that computes this is incompatible with the current version of the code. In addition, filtering on partition for edges does not seem to currently work - this makes identification of cliques and balanced graphs more difficult. Along with this, Gephi can be very unstable at times, and some workarounds (like exporting a newly created graph and re-importing it to ensure compatibility with multiple edges) can be a hassle.\nSummary In short, I think Gephi is a good choice for the classroom, but one that will require some serious work from the instructor. I would HIGHLY recommend that you teach Gephi in a classroom setting, where JVM and OS choices are restricted and supported by IT staff. I would like to see more educators using Gephi so we can pressure the developers (or encourage interested students!) to add more functionality to the core of the software.\n\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/2-of-n-gephi-d3-js-and-maps-success.html",
    "href": "posts/2-of-n-gephi-d3-js-and-maps-success.html",
    "title": "2 of N: Gephi, D3.js, and maps: Success!",
    "section": "",
    "text": "[caption id=“attachment_251” align=“alignright” width=“300”] A working, geographically accurate map using Gephi, D3.js, and Leaflet. NOTE: Link subject to change.[/caption]\nIn my previous post I outlined how I used D3.js to display a “raw” JSON output from Gephi. After some hacking around, I am now able to display my Gephi data on an interactive leaflet map!\nThis is a departure from other work on the subject for a few reasons:\n\nNot all of my data has geographic information - indeed in many cases a specific longitude / latitude combination is inappropriate and would lend a false sense of permanence to anyone looking at the map. In my case I have names of Greek garrison commanders which have some relation to a place, but it is unclear in some instances if they are actually at a specific place, have dominion over the location, or are mentioned in an inscription for some other reason. Therefore, I need to locate data that has a fuzzy relation to a location (ancient people who may originate, reside, work, and be mentioned in different and / or unknown locations) and locations that may themselves have fuzzy or unknown geography. This is a problem for just about every ancient to pre-modern project, as we do not have a wealth of location information, or even a clear idea of where some people are at any particular moment.\nI want to show how social networks form around specific geographic points which are known, and have those social networks remain “reactive” on zooms, changing map states, etc. This can be expanded to encompass epistolary networks, knowledge maps, etc - basically anything that links people together who may not be locatable themselves.\nGephi does not output in GeoJSON, and the remaining export options that are geographically oriented require that *all* nodes have geographic information. As this is not my case (see above), the standard export options will not work for me. Also, as part of my work on BAM, I want to create a framework that is as “plug and play” as possible, so that we can simply take Gephi files and drop them into the system to make new modules. Therefore this work has to be reproducible with a minimum of tweaking.\n\nSo, let us get to the code!\nFirst things first: You need to make your html, bring in your javascript,and style some elements. I put the css in the file for testing - it will be split off later.\n[code language=“javascript”]\n&lt;!DOCTYPE html&gt;\n&lt;head&gt; &lt;meta name=‘viewport’ content=‘width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no’ /&gt; &lt;!– Mapbox includes below –&gt; &lt;script src=‘https://api.mapbox.com/mapbox.js/v2.2.2/mapbox.js’&gt;&lt;/script&gt; &lt;link href=‘https://api.mapbox.com/mapbox.js/v2.2.2/mapbox.css’ rel=‘stylesheet’ /&gt; &lt;script src=“https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js”&gt;&lt;/script&gt; &lt;script src=“http://d3js.org/d3.v3.js”&gt;&lt;/script&gt; &lt;/head&gt; &lt;meta charset=“utf-8”&gt; &lt;!– Will split off css when done with testing –&gt;\n&lt;style&gt; .node circle { stroke: grey; stroke-width: 10px; }\n.link { stroke: black; stroke-width: 1px; opacity: .2; }\n.label { font-family: Arial; font-size: 12px; }\n#map { height: 98vh; }\n#attributepane { display: block; display: none; position: absolute; height: auto; bottom: 20%; top: 20%; right: 0; width: 240px; background-color: #fff; margin: 0; background-color: rgba(255, 255, 255, 0.8); border-left: 1px solid #ccc; padding: 18px 18px 18px 18px; z-index: 8998; overflow: scroll; } &lt;/style&gt;\n&lt;body&gt;\n&lt;div id=‘attributepane’&gt;&lt;/div&gt;\n&lt;div id=‘map’&gt; &lt;/div&gt;\n[/code]\nNext, make a map.\n[code language=“javascript”] &lt;script&gt; var map = L.mapbox.map(‘map’, ‘yourmap’, { accessToken: ‘yourtoken’ });\n//set the initial view. This is pretty standard for most of the ancient med. projects map.setView([40.58058, 36.29883], 4);\n[/code]\nPretty basic so far. Next we follow some of the examples that are already in the wild to initiate D3 goodness:\n[code language=“javascript”]\nvar force = d3.layout.force() .charge(-120) .linkDistance(30);\n/* Initialize the SVG layer */ map._initPathRoot();\n/* We simply pick up the SVG from the map object */ var svg = d3.select(“#map”).select(“svg”), g = svg.append(“g”);\n[/code]\nNext, we bring in our json file from Gephi. Again, this is pretty standard:\n[code language=“javascript”]\nd3.json(“graph.json”, function(error, json) {\nif (error) throw error;\n[/code]\nNow we get into the actual modifications to make the json, D3, and leaflet all talk to each other. The first thing to do is to modify the colors (from http://stackoverflow.com/questions/13070054/convert-rgb-strings-to-hex-in-javascript) so that D3 displays what we have in Gephi:\n[code language=“javascript”]\n//fix up the data so it is what we want for d3 json.nodes.forEach(function(d) { //convert the rgb colors to hex for d3 var a = d.color.split(“(”)[1].split(“)”)[0]; a = a.split(“,”);\nvar b = a.map(function(x) { //For each array element x = parseInt(x).toString(16); //Convert to a base16 string return (x.length == 1) ? “0” + x : x; //Add zero if we get only one character }) b = “#” + b.join(““); d.color = b;\n[/code]\nNext, we need to put in “dummy” coordinates for locations that do not have geography. This is messy and could probably be removed with some more efficient coding later. For the nodes that do have geography, the map.latLngToLayerPoint will translate the values into map units, which places them where they need to go. These are simply lat lon attributes in the Gephi file. I also set nodes that are fixed / not fixed, based on the presence of lat/lon data.\n[code language=“javascript”]\nif (!(“lng” in d.attributes) == true) { //if there is no geography, then allow the node to float around d.LatLng = new L.LatLng(0, 0); d.fixed = false; } else //there is geography, so place the node where it goes { d.LatLng = new L.LatLng(d.attributes.lat, d.attributes.lng); d.fixed = true; d.x = map.latLngToLayerPoint(d.LatLng).x; d.y = map.latLngToLayerPoint(d.LatLng).y; } })\n[/code]\nNow to setup the links. As we are keyed on attributes and not an index value, we need to follow this fix:\n[code language=“javascript”]\nvar edges = []; json.edges.forEach(function(e) { var sourceNode = json.nodes.filter(function(n) { return n.id === e.source; })[0], targetNode = json.nodes.filter(function(n) { return n.id === e.target; })[0];\nedges.push({ source: sourceNode, target: targetNode, value: e.Value }); });\nvar link = svg.selectAll(“.link”) .data(edges) .enter().append(“line”) .attr(“class”, “link”);\n[/code]\nNow to setup the nodes. I wanted to do a popup on a mouseclick event, but for some reason this is not firing (mousedown and mouseover do work, however). The following code builds the nodes, with radii, fill, and other information pulled from the JSON file. It also toggles a div that is populated with attribute information from the JSON. There is still some work to do at this part: the .css needs to be cleaned up, images need to be resized, and the attribute information for the nodes should be a configurable option when importing the JSON.\n[code language=“javascript”]\nvar node = svg.selectAll(“.node”) .data(json.nodes) .enter().append(“circle”) //display nodes and information when a node is clicked on //for some reason the click event is not registering, but mousedown and mouseover are. .on(“mouseover”, function(d) {\n//put in blank values if there are no attributes var titleForBox, imageForBox, descriptionForBox = ’‘; titleForBox =’ &lt;h1&gt;’ + d.label + ’&lt;/h1&gt;\n’;\nif (typeof d.attributes.Description != “undefined”) { descriptionForBox = d.attributes.Description; } else { descriptionForBox = ’’; }\nif (typeof d.attributes.image != “undefined”) { imageForBox = ‘&lt;img src=“’ + d.attributes.image + ‘” align=“left”&gt;’; } else { imageForBox = ’’; }\nvar htmlForBox = imageForBox + ’ ’ + titleForBox + descriptionForBox; document.getElementById(“attributepane”).innerHTML = htmlForBox; toggle_visibility(‘attributepane’); }) .style(“stroke”, “black”) .style(“opacity”, .6) .attr(“r”, function(d) { return d.size * 2; }) .style(“fill”, function(d) { return d.color; }) .call(force.drag);\n[/code]\nNow for the transformations when the map state changes. The idea is to keep the fixed nodes in the correct place, but to redraw the “floating” nodes when the map is zoomed in and out. The nodes that need to be transformed are dealt with first, then the links are rebuilt with the new (or fixed) x / y data.\n[code language=“javascript”]\n//for when the map changes viewpoint map.on(“viewreset”, update); update();\nfunction update() {\nnode.attr(“transform”, function(d) { if (d.fixed == true) { d.x = map.latLngToLayerPoint(d.LatLng).x; d.y = map.latLngToLayerPoint(d.LatLng).y; return “translate(” + map.latLngToLayerPoint(d.LatLng).x + “,” + map.latLngToLayerPoint(d.LatLng).y + “)”; } } );\nlink.attr(“x1”, function(d) { return d.source.x; }) .attr(“y1”, function(d) { return d.source.y; }) .attr(“x2”, function(d) { return d.target.x; }) .attr(“y2”, function(d) { return d.target.y; });\nnode.attr(“cx”, function(d) { if (d.fixed == false) { return d.x; } }) .attr(“cy”, function(d) { if (d.fixed == false) { return d.y; } })\n//this kickstarts the simulation, so the nodes will realign to a zoomed state force.start(); }\n[/code]\nNext, time to start the simulation for the first time and close out the d3 json block:\n[code language=“javascript”]\nforce .links(edges) .nodes(json.nodes) .start(); force.on(“tick”, update);\n}); //end\n[/code]\nFinally, time to put a function in to toggle the visibility of the div (from here) and close out our file:\n[code language=“javascript”]\nfunction toggle_visibility(id) { var e = document.getElementById(id); if (e.style.display == ‘block’) e.style.display = ‘none’; else e.style.display = ‘block’; } &lt;/script&gt; &lt;/body&gt;\n[/code]\nThere you have it- a nice, interactive map with a mix of geographic information and social networks. While I am pleased with the result, there are still some things to fix / address:\n\nThe click even not working. This is a real puzzler.\nTweaking the distances of the simulation - I do not want nodes to be placed half a world away from their connections. This may have to be map zoom level dependent.\nStyle the links according to Gephi and provide popups where applicable. This should be easy enough to do, but simply hasn’t been done in this code.\nTweak the visibility of the connections and nodes. While retaining an option to show the entire network at once, my idea is to have a map that starts out with JUST the locations, and then makes the nodes that are connected to that location visible when you click on it (which would also apply to the unlocated nodes - i.e. you see what they are connected to when you click on them).\nConnected to the above point, the implementation of a slider to show nodes in a particular timeframe. As my data spans a period from the 600s BCE to the 200s CE, this would provide a better snapshot of a particular network at a particular time.\nImplement a URI based system - you will be able to go to address/someEntityName and that entity will be selected with its information pane and connected neighbors displayed. This will result in an RDF file that will be sent to the Pelagios Project.\nFix up the .css for the information pane.\n\nI will detail further steps in a later post.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/what-do-you-do-with-36409-places-and-6506-connections-some-cartographic-representations-of-pleiades-data.html",
    "href": "posts/what-do-you-do-with-36409-places-and-6506-connections-some-cartographic-representations-of-pleiades-data.html",
    "title": "What do you do with 36,409 places and 6,506 connections? Some cartographic representations of Pleiades data",
    "section": "",
    "text": "Two projects that I am involved with, Pleiades and the World-Historical Gazetteer at the University of Pittsburgh, have been devoting considerable time and energy to modeling conceptual places and their connections, so I thought it was worth discussing a few of our observations and presenting some preliminary steps to visualize what we are doing.\nFirst, a somewhat crowded overview of all of the Pleiades data set with map symbols representing different place types.\n[caption id=“attachment_1171” align=“alignnone” width=“3507”] Figure 1: All Pleiades places[/caption]\nAt this level of zoom the map is nearly incomprehensible, but it does reveal some interesting aspects of our data set. The Grid like structure in India and central Asia is the result of “dumping” places for which we have insufficient data into the middle of Barrington Atlas grid squares. For the editorial board such a view is actually quite useful, as it highlights where we need to clean our data and focus on creating better locations.\nAnother way to show the reach of the Pleiades project is through a choropleth map, which shades different countries according to the number of Pleiades places within them.\n[caption id=“attachment_media-14” align=“alignnone” width=“4677”] Figure 2: Choropleth Map[/caption]\nThis is interesting, but I think it gives a fairly misleading sense of Pleiades coverage. From this map a reader would be unable to tell the extent of our data into Russia, China, and other countries where our locations are clustered around certain areas, not evenly spread throughout the country. It does highlight the areas where we have fairly extensive coverage, namely Italy, Greece, and Turkey.\nTo get around these issues, very often projects like ours use heat-maps to show both the concentration and extent of their data. I find this particular approach to be more aesthetically pleasing than simply throwing all of the points on the map, but due to the nature of a heat-map, I am still not convinced that it accurately depicts the extent of our coverage.\n[caption id=“attachment_media-19” align=“alignnone” width=“4677”] Figure 3: Heat Map[/caption]\nOne of my issues with heat-maps is how the colors “bleed” into areas where there are not points. While this can be adjusted and refined by decreasing the radius around each point, if taken too far the heat-map will simply show isolated dots of color instead of the expected continuous whole.\nOne experiment that I have done is to try and combine heat maps with a Voronoi diagram. The basic idea behind this approach is that the GIS system creates a polygon around each point, and any spot within that polygon is closer to that particular point than any other known point. This helps Pleiades editors, as a “hotspot” in one polygon indicates that there are multiple places “stacked” on one another on the same point, which is a good indication that we are dealing with inaccurate data. Conversely, a “hotspot” that extends through multiple polygons is expected behavior, and signifies that there is a dense cluster of points that are in close proximity but nevertheless still are in distinct locations.\n[caption id=“attachment_media-24” align=“alignnone” width=“4677”] Figure 4: Detail of Voronoi Polygons and a Heat-Map[/caption]\nThis is a very aesthetically pleasing map, but it is still difficult to quickly identify the correspondence between points, polygons, and the heat map. Using a hex-bin map (which is essentially a choropleth map with small hex shapes) styled like a heat map perhaps provides the cleanest and most comprehensible view of both our data coverage and density.\n[caption id=“attachment_media-11” align=“alignnone” width=“4677”] Figure 5: Hex-bin map with heat map coloration[/caption]\nOf all the representations mentioned here (and many tests which were far too incomprehensible to show), I believe this map offers by far the best combination of understandability, honesty, and presentation. It clearly shows the concentration of our data in the Mediterranean like a heat map, but does a far better job of showing the precise location of the data points. It also shows a far more honest depiction of the number of points per country and the actual location of those points, which is not the case with a choropleth map at a country scale.\nWhat these maps do not capture is the presence of connections in the Pleiades data set. As part of our evolving data modeling and best practices, we are now experimenting with a more robust system for expressing relationships between different places in our data set. These relationships could be political, geographic, or highly conceptual. One highly interesting product of this approach is that we can start thinking of the Pleiades gazetteer as a description of a network of places, not just as a list of their names and locations.\nAs a result, it is now possible to graph some of the relationships in our data. This is highly experimental and very incomplete, but I hope that by sharing our first steps in this direction that we can generate some discussion on our approach.\nThe first thing that I did was to download the Pleiades data set, then extract the connections information, creating a spread sheet that listed each connection as a source - target combination that social network analysis software would understand. Essentially any place that connected to another place was the source, while the place connected to was the target. This was then put into Gephi, where different “communities”, or places with denser connections to each other, are indicated by different colors.\n[caption id=“attachment_1177” align=“alignnone” width=“1024”] Figure 6: Detail of the Pleiades connections graph[/caption]\nThe figure above is a detail of a portion of the resulting graph. You can see communities clustering around regions like Sicily and Sardinia, or around extremely important cities like Rome. The square on the outer reaches of the graph is simply a number of unconnected places that are pushed to the edges by the Gephi visualization software. While this is an interesting and somewhat compelling visualization, it is devoid of any geographic context. Luckily, Gephi has a plugin that places nodes (in our case the places) in a geographic location of there is data available. As we have location data for most of our places, we can use this plugin, which yields the result below.\n[caption id=“attachment_1178” align=“alignnone” width=“1024”] Figure 7: Pleiades places as a geospatial network[/caption]\nNow we are getting somewhere! The broad outlines of the Mediterranean are visible, as are features like the Nile river and even the outline of India. However, this network is still not on a geographic map (the Gephi globe plugin does not exactly match the coordinate system used by the geography plugin, and also it is based on modern geography), so we are somewhat missing the larger spacial context. Unfortunately there is not an easy way to export the specially enhanced network with Gephi’s statistics and colors - the .kml plugin does capture the color, but lumps all of the statistics into a single description tag.\nAfter some experimentation with exporting, importing, and reexporting in Gephi and QGIS, I finally found a solution by importing the .kml exported from Gephi into QGIS and exporting that as a .csv file which can then be manipulated in OpenRefine to “extract” all of the information from the description field.  From there, the .csv file can be re-imported into QGIS, which results in the visualization below.\n[caption id=“attachment_media-29” align=“alignnone” width=“4677”] Figure 8: Pleiades spatial connections overview map[/caption]\nWhile somewhat crowded and messy, a closer of Italy view shows the power of this visualization.\n[caption id=“attachment_media-34” align=“alignnone” width=“4677”] Figure 9: Network around Rome without labels[/caption]\n[caption id=“attachment_media-39” align=“alignnone” width=“4677”] Figure 10: Network around Rome with labels[/caption]\nThese visualizations show the networks of connections within a spatial context, and are an intriguing way to approach entities like kingdoms, political entities, or other place groupings. We are already experimenting with placing regions and larger entities (like Sardinia and Sicily) as the “midpoint” between all of their constituent connections, which you can see displayed on the maps above.\nHowever, I want to take this idea one step further and eliminate the representative point entirely from such places. To do so, I decided that a mono modal network, or a network of just one place type, would be an interesting way to represent these connections. In short, any place that connected to the place Sardinia would now connect directly to all of the other places that connected to Sardinia, and the place marker of Sardinia would be eliminated from the network entirely. This resulted in a very interesting visualization where the density of network connections almost resembles a polygon.\n[caption id=“attachment_media-44” align=“alignnone” width=“4677”] Figure 11: Single mode network representation of Pleiades data[/caption]\nEven though I am still figuring out a method to transfer the color of the links from Gephi to QGIS, this type of representation has tremendous potential. If we can class different connections and pull those form the data set, we can begin to represent political areas, land masses, and other groupings as the sum of their shared connections in geographic space. So, instead of drawing arbitrary polygons, it is the connections themselves that create the “area” of a place. If these connections are able to respect underlying geography (roads, mountain passes, navigable rivers, springs, and other features), I think we may have a very powerful way of representing economic regions, areas of social interaction, political control, etc, and explore how those different networks interact and influence each other in geographic space.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/1-of-n-gephi-d3-js-and-maps.html",
    "href": "posts/1-of-n-gephi-d3-js-and-maps.html",
    "title": "1 of N: Gephi, D3.js, and maps",
    "section": "",
    "text": "Update (11/12/15): See this post to integrate the following code with leaflet.\nAfter finding no real way to use background maps with SigmaJs, I stumbled on this example of combining leaflet with D3.js: http://bost.ocks.org/mike/leaflet/. The example is more closely aligned with what I want to achieve, which is using a display library to show a social network that respects / interacts with underlying geography. This would be a very valuable visualization for both TBib/BAM and my own work on garrisons, and completing it will allow me to get back to other tasks, like pounding out Greek inscriptions.\nFor this work I am not tied to Gephi, but I do like its interface and low learning curve, which is valuable for pedagogical and collaborative use. So, my first order of business is getting a Gephi project to talk nicely with D3.js. There is, of course, a nice example already in the wild: http://bl.ocks.org/susielu/9526340. However, this presented some serious problems, which I will outline to (hopefully!) help others who may be going down this path. So, refer back to http://bl.ocks.org/susielu/9526340 for the code template - what follows below are additions / modifications.\nFor this project, I want to recreate the image to the right, which was created in Gephi. If you read my previous post on this topic, this image uses a geo-layout plugin to place locations from Pleiades in their correct geographic placement, then uses other layouts to place the people and other non locatable nodes. The eventual goal is to make an interactive network map above an interactive geographic map, so simply exporting these out as a flat svg file will not provide the functionality I need.\nMy first attempt to simply plug in my own data met with disaster. First, I got hit with an “Uncaught TypeError: Cannot read property ‘weight’ of undefined” error and absolutely no graph. Looking into it, I noticed that the example assumed that nodes would be referenced by their position in an index, NOT by their own id.\n[code language=“javascript”]\nvar links = json.edges.map(function(d){ return { ‘source’: parseInt(d.source), ‘target’: parseInt(d.target) } }) [/code]\nMy linkages use a unique ID text attribute, which plays havoc with this function. However, this seems like a simple fix: simply remove the parseInt() function, and the actual linkages should work.\n[code language=“javascript”]\nvar links = json.edges.map(function(d){ return { ‘source’: d.source, ‘target’: d.target } }) [/code]\nGetting closer: I see a network graph….only minus the network. Yikes. So, what is going wrong?\nIt seems that linking nodes by attribute instead of index is a somewhat common problem in D3.js, with a good solution here: http://stackoverflow.com/questions/23986466/d3-force-layout-linking-nodes-by-name-instead-of-index. Following this example, I modified my code by adding the following:\n[code language=“javascript”]\nvar edges = []; links.forEach(function(e) { // Get the source and target nodes var sourceNode = nodes.filter(function(n) { return n.id === e.source; })[0], targetNode = nodes.filter(function(n) { return n.id === e.target; })[0];\n// Add the edge to the array edges.push({source: sourceNode, target: targetNode}); });\n…\nvar force = d3.layout.force() .nodes(nodes) .links(edges)\n…\nvar link = svg.selectAll(“.link”) .data(edges)\n[/code]\nFinally, the links show! The nodes, however, are of a uniform size. I want the nodes to reflect their size in Gephi. Luckily this was an easy fix: adding\n[code language=“javascript”]\n.attr(“r”, function(d) { return d.size * 3; })\n[/code]\nto\n[code langauge=“javascript”] node.append(“svg:circle”) [/code]\ndid the trick. I also wanted to add colors from Gephi - the following code does so (with a conversion from RGB to hex provided by http://stackoverflow.com/questions/13070054/convert-rgb-strings-to-hex-in-javascript) :\n[code language=“javascript”]\nvar a = d.color.split(“(”)[1].split(“)”)[0]; a = a.split(“,”);\nvar b = a.map(function(x){ //For each array element x = parseInt(x).toString(16); //Convert to a base16 string return (x.length==1) ? “0”+x : x; //Add zero if we get only one character })\nb = “#”+b.join(““);\nreturn { ‘id’ : d.id, ‘x’ : d.x, ‘y’ : d.y, ‘fixed’: true, ‘label’ : d.label, ‘size’ : d.size, ‘color’ : b, } })\n[/code]\nand\n[code language=“javascript”]\n.style(“fill”, function (d) { return d.color; })\n[/code]\nadded to\n[code language=“javascript”]\nnode.append(“svg:circle”)\n[/code]\nThis produces a graph that looks correct except for one MAJOR problem: It seems the Y axis is inverted from the original! This is obviously not acceptable if I am trying to capture actual coordinates for a map. All is not lost: I do remember this being a problem in the SigmaJS exporter. A fix is provided here: https://github.com/oxfordinternetinstitute/gephi-plugins/issues/5#issuecomment-22291683. For me, this was as simple as adding the following code:\n[code language=“javascript”]\nfinalY = -d.y; return { ‘id’ : d.id, ‘x’ : d.x, ‘y’ : finalY, ‘fixed’: true, ‘label’ : d.label, ‘size’ : d.size, ‘color’ : b, }\n})\n[/code]\nto the\n[code language=“javscript”]   var nodes = json.nodes.map(function(d) [/code]\nblock.\nThe next task will be to finalize some functionality for the D3.js portion of the graph, then on to integrating the whole mess with leaflet. Then, when I have all of this in order, time to re-write it to accept all manner of different inputs / etc for BAM. More on both of these ideas later.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/ancient-itineraries-the-digital-lives-of-art-history.html",
    "href": "posts/ancient-itineraries-the-digital-lives-of-art-history.html",
    "title": "Ancient Itineraries: The Digital Lives of Art History",
    "section": "",
    "text": "I am very happy to announce that I have been chosen as a participant for Ancient Itineraries: The Digital Lives of Art History institute, which is supported by the Getty Foundation as part of their Digital Art History initiative.\n \nA (VERY!) brief synopsis: The institute will focus on three areas of concern to digital art history: provenance, geographies, and visualization. We will create detailed specifications, assess different methodologies, and create a detailed proof of concept for each of these three areas. The results of this work will be translatable to different project plans and research opportunities at the close of the institute.\n \nGiven the detailed description of the institute (linked above) and the various specialties and strengths of the organizers, I think this will be a fascinating exploration of the intersection of art history, ancient history, linked data, geospatial research, material culture, and digital humanities. I expect that this institute will not only create outstanding scholarly output, but will serve as the core of a new, robust community of scholars interested in linked data, material culture, and art history.\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts/quick-and-dirty-footnotes-for-gephi-sigmajs.html",
    "href": "posts/quick-and-dirty-footnotes-for-gephi-sigmajs.html",
    "title": "Quick and Dirty Footnotes For Gephi / SigmaJS",
    "section": "",
    "text": "Before I begin, I once again want to recognize the excellent SigmaJS Exporter plugin for Gephi. This really does mitigate a lot of the grunt work involved in quickly making a usable, interactive social network graph. However, sometimes you just want another feature or some further refinement - in my case adding workable footnotes to information on each node.\nFor those of us in the humanities, citations are sine qua non for scholarship. However, there are few good was to maintain linkable citations on the web that are not hardcoded beforehand, or reliant on javascript trickery. What I wanted to do was find a tool or a method to easily move text and citations contained in my dissertation to a description field in a Gephi-based application without manually entering footnotes, footnote numbers, or linking them myself, as I have over 2,000 footnotes to deal with.\nWhat I found is a bit of a hack, and certainly can be improved, but it works. First, you are going to want to have your document in a format that is readable by OpenOffice / LibreOffice / etc. What you need to do is select the bit of text you are interested in, dump it into a new file (making sure to include your footnotes!) and then export that file as XHTML.\nOnce this is complete, you will have a lovely, fully encapsulated xml file of your text - including all formatting, footnotes, etc. However, we want to eliminate some of the elements produced by this process. Open this file in your favorite text editor. You will notice that you have code similar to the following at the top of the document:\n[code language=“html”]\n&lt;!DOCTYPE html PUBLIC “-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN” “http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd”&gt;\n\n\n\n\n\n&lt;ul&gt;\n&lt;li&gt;no title specified\n\n\n\n\n\n\n\n\n    [/code]\n\nThis can all be eliminated. Make sure you retain the\n[code language=“html”]"
  },
  {
    "objectID": "posts/code-for-bam-part-1-of-n-gephi-and-maps.html",
    "href": "posts/code-for-bam-part-1-of-n-gephi-and-maps.html",
    "title": "Code for BAM: Part 1 of N. Gephi and Maps",
    "section": "",
    "text": "This is the first in a series of posts where I will be detailing some of the code and development of BAM. Some of these techniques may be old hat for some users or simple hacks, but they might be useful for anyone else who is trying to do similar work.\n[caption id=“attachment_97” align=“alignright” width=“300”] Terra Biblica with both the social network graph and map displaying information on Jesus.[/caption]\nIn this post, I will detail how I got Gephi data (produced by the SigmaJs Exporter) to communicate with an OpenLayers 2 map. When a user clicks on any entity in the network graph the map panel will adjust to show the locations and frequency of that entity in geographic space. At the same time, any clicks on an entity name on the map (provided by a popup) will adjust the social network graph to highlight that entity. This code is built on javascript, PHP, and a PoistGIS backend. At some point in the future BAM may transition to OpenLayers 3, but for now we are sticking with 2 as it formed the basis for À-la-Carte, Digital Strabo, and other digital efforts that BAM builds upon and extends.\nFor a working demonstration of the final result, see http://awmc.unc.edu/awmc/applications/bam/luke/. All of the code mentioned in this post, and created for BAM, is available at: https://github.com/Big-Ancient-Mediterranean/BAM.\nStep 1: Get your data in order!\nBefore attempting any of this, you need to ensure that the entities that you are using in Gephi and the ones you have in your database have a consistent, unique ID. So, if Andrew has an id of 1234567 in Gephi, you need to associate 1234567 with different locations, texts, etc in your database that are also related to Andrew. Failure to do so will make it VERY difficult, if not impossible, to get all of the different components to talk to each other.\nNext, you actually need to build your network in Gephi and export it out. Building the network itself is beyond the scope of this post, but you need to install and familiarize yourself with the excellent SigmaJs Exporter created by Scott Hale at the Oxford Internet Institute. Essentially what we are doing is taking the output of the SigmaJs Exporter, cutting it down, and making it communicate with a dynamic, interactive map on the same webpage.\nAfter exporting your network using the SigmaJs Exporter, you should have a directory structure that roughly looks like the screenshot to the right. You want to upload everything but htaccess_example, web.config, and index.html to your webserver.\nWe then need to add this network to an HTML file that already has a map. In our case, we are modifying the code behind Strabo Online and SNAGG. I may detail how to create a map in another post, but there are plenty of resources online to get you going on a basic map.\nWe are going to mimic the functionality of the index.html file that we excluded in our own html file. First, we need to include the various javascript files and libraries used by the application:\n[code language=“html”]\n\n\n\n\n\n  \n[/code]\nNow we need to place some divs to hold the content from our social network. These can be styled at your leisure.\n[code language=“html”]\n\n\n\n\n\n\n\nReturn to the full network\n\n\n\n\n\n\n\n\n\n\nConnections:\n\n\n\n\n\n\n\n\n\n\n\n[/code]\nNow that we have all the functionality of the SigmaJs Exporter in our map, we need to make the components talk to each other. First, we need to identify what node is active on the sigma.js div, and use that information to select the appropriate data for our map. The function nodeActive in SigmaJs identifies what / when a node is active - so we will extend this to pass that information to a variable (for a more detailed explanation on how to extend a javascript function, see http://coreymaynard.com/blog/extending-a-javascript-function/).\nWe are also going to create a separate function to deal with adjusting the map itself, called tBibPersonConnections, which will be called in our new, extended function:\n[code language=“javascript”] (function() { //first copy the old function in the new one var old_nodeActive = nodeActive;\n//new function with the same name as the old one - this overrides the old function nodeActive = function() {\n//we are going to build the map from the person_id that is called from the node // this is a separate function that will be explained below tBibPersonConnections(arguments[0], tBibPeoplelayer); activePerson = arguments[0];\n// Calls the original function\\ var result = old_nodeActive.apply(this, arguments);\n// now return the result return result; } })(); [/code]\ntBibPersonConnections is where the work really happens. Lets examine this function slowly.\n[code language=“javascript”]\nfunction tBibPersonConnections(personNameChoice, tBibPeoplelayer) { var dataStringForFeature =‘pid=’ +personNameChoice +‘&amp;amp;amp;amp;amp;start=0’; tBibPeoplelayer.destroyFeatures(); tBibfeaturesOnMap =[];\n$.ajax({ dataType: “json”, type:‘GET’, data:dataStringForFeature, url:‘tbib_mapmaker.php’, success:function(dataJson) { for (var i = 0; i &amp;amp;amp;amp;lt; dataJson.features.length; i++){ var untransformed_feature = geojson_format.read(dataJson, “FeatureCollection”); //for some reason this is going into an array. Going to hardcode for now for (var j = 0; j &amp;amp;amp;amp;lt; dataJson.features.length; j++){ if (tBibfeaturesOnMap.indexOf(untransformed_feature[j].attributes.pid) &amp;amp;amp;amp;lt; 0){ tBibPeoplelayer.addFeatures(untransformed_feature[j]); tBibfeaturesOnMap.push(untransformed_feature[j].attributes.pid); } } tBibPeoplelayer.refresh({force:true}); } }, error: function (xhr, ajaxOptions, thrownError) { alert(xhr.responseText); } });\n} [/code]\nThe function takes the ID of the person selected and layer that houses all of the feature information as arguments.\nThe first thing we do is create parameters for the PHP file that will return all of the place / feature information that is associated with an individual person. Do not worry about the “start” parameter for now, as it is only used when resetting the map to an initial state. The lines\ntBibPeoplelayer.destroyFeatures(); tBibfeaturesOnMap =[];\nfirst clear the map layer of all features, and then sets up an array to hold all of the new features that we will be adding to the map.\nThe AJAX call to tbib_mapmaker.php actually queries our database, and returns each feature that is associated with an individual, the number of times the individual is mentioned with the feature, and the geographic location of the feature. While the actual sql calls are specific to this application / database, I will show what we are doing for combining Pleiades data, BAM data, and the map:\n[code language=“PHP”] \\(query = \"select pplaces.title, count(pplaces.title), max (pplaces.id) as pleaides\\_id, ST\\_AsGeoJSON(ST\\_Transform(max(pplaces.the\\_geom), 3857)) as geom from pplaces JOIN tbib\\_pleiades ON pplaces.id = tbib\\_pleiades.pleiades\\_id JOIN tbib\\_network ON tbib\\_pleiades.verse = tbib\\_network.reference where character\\_1 = '\\)pidParam’ or character_2 = ‘$pidParam’ GROUP BY pplaces.title”; [/code]\nWe are interested in every occurrence of an individual, so we do not care if the person is the target or the source. Our tbib_network table is exactly the same as the table used to build our Gephi network, and all people are assigned a unique ID that remains consistent across tables.\nAt the end of the .php file, all of the results are returned in json format:\n[code language=“PHP”] //make a geojson object while(\\(row =pg\\_fetch\\_assoc(\\)qry_result)){ //resize for map \\(sizeForMap = ((\\)row[count] / 10) + 1);\n//arrange for map \\(arr\\[\\] = array( \"type\" =&gt; \"Feature\", \"geometry\" =&gt; json\\_decode(\\)row[geom]), “properties” =&gt; array( “title” =&gt;\\(row\\[title\\], \"count\" =&gt;\\)sizeForMap, “pid” =&gt; $row[pleaides_id] ), ); } //encode into geojson \\(geojson = '{\"type\":\"FeatureCollection\",\"features\":'.json\\_encode(\\)arr).’}’; echo $geojson; ?&gt; [/code]\nIn the future, this database work will be mirrored by static json files, to allow for the easy export / import of BAM material.\nWhen the PHP file returns a json string, the function then pulls it apart, creates new OpenLayers features, and then adds them to the map:\n[code language=“javascript”] success:function(dataJson) { for (var i = 0; i &lt; dataJson.features.length; i++){ var untransformed_feature = geojson_format.read(dataJson, “FeatureCollection”); for (var j = 0; j &lt; dataJson.features.length; j++){ if (tBibfeaturesOnMap.indexOf(untransformed_feature[j].attributes.pid) &lt; 0){ tBibPeoplelayer.addFeatures(untransformed_feature[j]); tBibfeaturesOnMap.push(untransformed_feature[j].attributes.pid); } } tBibPeoplelayer.refresh({force:true}); } }, [/code]\nThe result is a layer that changes depending on what person is clicked.\n[caption id=“attachment_131” align=“alignright” width=“300”] A user selected popup[/caption]\nThat is great for changing the map, but what about changing the nodes on the network graph for when an individual is selected on the map?\nAs we are displaying people names, not ID as clickable information in our popups, we need a way to translate the names to the IDs used by SigmaJs. This is simply a trivial php script that looks up an ID from a name table. Once the ID is returned, we simply activate the node with a call to the nodeActive function that we extended earlier and to our tBibPersonConnections function.\nFirst, however, we have to listen for the event where the popup on the map is clicked:\n[code language=“javascript”]\n//this is the popup listner\n$(‘#popupSnagTable tbody’).on( ‘click’, ‘td’, function () { //now to start stripping out to what we need var columnName = \\(('#popupSnagTable thead tr th').eq(\\)(this).index()).html().trim(); if (columnName == ‘Reference’)\n{ var ActiveRef = \\((this).html().trim(); ActiveRef = ActiveRef.replace('Lk ',''); var ActiveRefSpilt = ActiveRef.split(\":\"); activeChapter = ActiveRefSpilt\\[0\\]; activeVerse = ActiveRefSpilt\\[1\\]; getPerseusText(\\)(this).html().trim(), 0); } //if the user clicks on a name, then we use this to make an ajax call if ((columnName == ‘Entity 1’) || (columnName == ‘Entity 2’)){ var personNameChoice = $(this).html().trim();\nvar dataString = ‘pid=’+personNameChoice;\n$.ajax( { type:‘GET’, data:dataString, url:‘bamIdFromNum.php’, success:function(data2)\n{\n//from the sigma.js gephi instance\nnodeActive(data2);\n//now to add all of the places the entity is on the map. Searching by ID\ntBibPersonConnections(data2, tBibPeoplelayer);\n}\n});\n[/code]\nThat is all there is to it - just a few listeners and a variable or two. There may be more efficient ways of doing this, but all the components are talking to each other!\n\n\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ryan M Horne",
    "section": "",
    "text": "This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Aeolian Alexanders Launches\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nTalk at UCSB on May 20th: Mediterranean Pathways: GIS, Network Analysis, and the Ancient World\n\n\n\n\n\n\ninformation\n\n\nmaps\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nApr 26, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do you do with 36,409 places and 6,506 connections? Some cartographic representations of Pleiades data\n\n\n\n\n\n\n\n\n\n\n\nNov 11, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nAncient Itineraries: The Digital Lives of Art History\n\n\n\n\n\n\n\n\n\n\n\nJul 19, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nNEH-Mellon Fellowship for Digital Publication\n\n\n\n\n\n\n\n\n\n\n\nDec 20, 2017\n\n\n\n\n\n\n\n\n\n\n\n\nSNA, Wikipedia, and the Hellenistic World\n\n\n\n\n\n\n\n\n\n\n\nApr 26, 2017\n\n\n\n\n\n\n\n\n\n\n\n\nAsia Minor in the Second Century CE: A New Wall Map From the Ancient World Mapping Center\n\n\n\n\n\n\nmaps\n\n\n\n\n\n\n\n\n\nFeb 26, 2017\n\n\n\n\n\n\n\n\n\n\n\n\nReportHate, whywereafraid, and SNA\n\n\n\n\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nNov 13, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nNoDAPL Twitter Analysis\n\n\n\n\n\n\nmaps\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nNov 6, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nGephi, Conspiracies, and SNA in the Classroom: Midterm Thoughts\n\n\n\n\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nSep 27, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nReflections on the BAM Conference\n\n\n\n\n\n\nbam\n\n\n\n\n\n\n\n\n\nJun 9, 2016\n\n\n\n\n\n\n\n\n\n\n\n\n2 of N: Gephi, D3.js, and maps: Success!\n\n\n\n\n\n\ncode\n\n\nmaps\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nNov 11, 2015\n\n\n\n\n\n\n\n\n\n\n\n\n1 of N: Gephi, D3.js, and maps\n\n\n\n\n\n\nbam\n\n\ncode\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nNov 7, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nQuick and Dirty Footnotes For Gephi / SigmaJS\n\n\n\n\n\n\ncode\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nOct 31, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nNetworks, Geography, and Gephi: Lots of Promise, but Lots of Work to be Done\n\n\n\n\n\n\nmaps\n\n\nsocial-networks\n\n\n\n\n\n\n\n\n\nOct 7, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nCode for BAM: Part 1 of N. Gephi and Maps\n\n\n\n\n\n\nbam\n\n\ncode\n\n\n\n\n\n\n\n\n\nSep 28, 2015\n\n\n\n\n\n\nNo matching items\n\nThis work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License."
  },
  {
    "objectID": "index.html#bio",
    "href": "index.html#bio",
    "title": "Ryan M Horne",
    "section": "Bio",
    "text": "Bio\nThis is the personal website of Ryan Horne, PhD. I focus on planning, managing, and preserving interdisciplinary digital humanities research projects. As a Research Consultant in the GIS and Visualization Group at the Office of Advanced Research Computing at UCLA, I collaborate with campus researchers at all levels of their digital scholarship, including conceptualization, implementation, and publication."
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "Ryan M Horne",
    "section": "About",
    "text": "About\nThis is the personal website of Ryan Horne, PhD. I focus on planning, managing, and preserving interdisciplinary digital humanities research projects. As a Research Consultant in the GIS and Visualization Group at the Office of Advanced Research Computing at UCLA, I collaborate with campus researchers at all levels of their digital scholarship, including conceptualization, implementation, and publication, as well as teach in the Digital Humanities Program and pursue my own research."
  },
  {
    "objectID": "index.html#research",
    "href": "index.html#research",
    "title": "Ryan M Horne",
    "section": "Research",
    "text": "Research\nMy research is at the nexus of media studies, digital humanities, and information science. My research focuses on how different social, economic, and political networks are created and maintained by current and historical communities that are on the margins of traditional power structures. An important component of this work is an exploration of how information and misinformation propagate and travel through networks, how these knowledge systems adapt to social and environmental change, and how to model these systems using new digital methods."
  },
  {
    "objectID": "index.html#teaching",
    "href": "index.html#teaching",
    "title": "Ryan M Horne",
    "section": "Teaching",
    "text": "Teaching\nMy pedagogical approach focuses on promoting student equity and supporting student growth through project-based assignments and digital techniques, with an emphasis on cooperative learning strategies and small group activities. I am committed to the development and support of new curriculum and interdisciplinary research initiatives that address social justice and systemic racism in academia and society, with most of my courses centered on student-led creation of digital projects that highlight social justice issues in digital media, spatial studies, and history."
  },
  {
    "objectID": "digital-portfolio.html#community-archives",
    "href": "digital-portfolio.html#community-archives",
    "title": "Digital Portfolio",
    "section": "",
    "text": "VSL Logo\n\n\n\n\nWorking in a collabiration between the Office of Advanced Research Computing and the Fowler Museum, I am the web developer and data designer / modeler for Visual and Sonic Landscapes of Muslims in Los Angeles, “…an effort to create a public space for self-representation and self-definition for Muslim Angelenos by Muslim Angelenos. A focus on community voices and ritual, music, murals, and other artworks as primary source materials defines this project.”\n  \n\n\n\n\n\n\nBLT Logo\n\n\n\n\nThis is an interdisciplinary project that studies cultural production and critical dialogue on racial issues. Started as a collaboration between UNC professors and working artists, Black Lunch Table brings together groups of African-American artists, academics, and activists throughout the United States. These groups have set dialogue topics, and the ensuing conversation is electronically archived and will be presented on an open access website. I led the design and development of new digital humanities methodologies and software for the project, including a combination of social network analysis and natural language processing to create innovative interfaces to catalog, search, and visualize the Black Lunch Table audio archives."
  }
]